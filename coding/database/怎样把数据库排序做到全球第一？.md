![](https://zhuanlan.zhihu.com/p/664312966)

[](https://www.zhihu.com/)

首发于[IT](https://www.zhihu.com/column/c_1705318239930867712)

写文章

![怎样把数据库排序做到全球第一？](https://picx.zhimg.com/70/v2-c7171c632c64c7dd9b05f5baeea34b83_1440w.awebp?source=172ae18b&biz_tag=Post)

# 怎样把数据库排序做到全球第一？

[![红星闪闪](https://pic1.zhimg.com/v2-7e1fc938ae12f5dce67d46b570d99ded_l.jpg?source=32738c0c&needBackground=1)](https://www.zhihu.com/people/hong-xing-shan-shan-17-75)

[红星闪闪](https://www.zhihu.com/people/hong-xing-shan-shan-17-75)

数据库资深工程师。在后台开发，高性能计算，分布式领域深耕。

已关注

157 人赞同了该文章

## 论文：[《These Rows Are Made for Sorting and That’s Just What We’ll Do》](https://link.zhihu.com/?target=https%3A//hannes.muehleisen.org/publications/ICDE2023-sorting.pdf)

## 背景

排序在数据库领域尤为重要。数据库的OrderBy算子直接依赖排序，其他核心算子，比如：MergeJoin、非等值Join、Window......都可能涉及到排序逻辑。数据库的内存超限而触发的落盘、索引构建等操作也强依赖于排序。

数据库中的排序和对数组的简单排序有很多相似的地方，但也有很多不同。在数据库中，通常是对多列数据进行排序，而且最终结果通常需要保留指定的非排序列（成为payload）。在这些额外限定下，怎样把排序的性能做到极致？

数据库通常有两种存储模式：行式存储（NSM, N-array Storage Model）和列式存储（DSM, Decomposition Storage Model） 哪种存储模式对数据库排序更友好？如果当前数据库的存储模式对排序不友好，我们可以做什么来弥补？

DuckDB据称在数据库领域把排序做到了**极致**，下图是[DuckDB官方网站给出的数据](https://link.zhihu.com/?target=https%3A//duckdb.org/2021/08/27/external-sorting.html)，单线程排序全面超越了竞对数据库，多线层排序也处于领先地位。

![](https://pic3.zhimg.com/80/v2-f7b27ed68abb9e180a75a903c91a960a_1440w.jpg)

![](https://pic3.zhimg.com/80/v2-2a8ffab752fcae4456e4e6f2270913b8_1440w.webp)

DuckDB是怎么做到的？未来DuckDB的排序还有哪些优化空间？这篇论文将揭晓答案。

此外，这篇文章解决性能问题的思路非常清晰：理论分析、实验设计、优化尝试、结果验证......每一步都有详细的论述，不仅仅是排序的性能优化方法，也是所有性能优化问题的\*\*“解题模板”\*\*，值得学习借鉴。

## 一 Introduce

## 1.1 数组排序

决定数组排序性能的因素：

- [算法复杂度](https://zhida.zhihu.com/search?q=%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6&zhida_source=entity&is_preview=1)：O(NlogN)的排序性能通常远优于O(N^2)的排序。
- 减少CacheMiss：尽可能顺序访问，或者限定随机访问的范围。
- 避免[分支预测](https://zhida.zhihu.com/search?q=%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B&zhida_source=entity&is_preview=1)失败：尽可能减少分支判断。
- 提升并行度：多线程排序。
- 特殊pattern检测：监测特殊的pattern（比如：基本有序、和目标排序刚好相反），针对不同的pattern采用不同的[排序算法](https://zhida.zhihu.com/search?q=%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95&zhida_source=entity&is_preview=1)。pdqsort是这方面的典范。

## 1.2 数据库排序

数据库排序也需要考虑前文提到的影响[数据排序](https://zhida.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E6%8E%92%E5%BA%8F&zhida_source=entity&is_preview=1)性能的因素，除此之外，还需要考虑：

- Compare和Move（Swap）[原子操作](https://zhida.zhihu.com/search?q=%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C&zhida_source=entity&is_preview=1)：比较两个值大小和移动值是排序算法中的基本操作，这两个操作的性能需要精心优化。此外，数据库的比较操作更为复杂，因为SQL中的OrderBy子句可以写的很复杂，且包括各种类型。
- 执行引擎的影响：现在的OLAP数据库系统主要分为向量化（VectorWise）和代码生（HyPer）成两大流派。虽然针对这两种执行引擎已经有过较为详细的比较研究，但是在排序这个细分领域还没有一个确切的结论。
- 行存和列存：这篇论文给出一个结论：**行式存储更有利于排序**，即使在列存场景下也是这样。也就是说，行排序获得的收益大于额外进行列转换的开销。这个结论非常有用，因为现在的OLAP数据库系统通常是列式存储，这意味着基本上所有OLAP数据库都可以通过行列转换来提升排序性能。行列转换运用于排序如下图所示，先将列式数据转换成行式，对行式数据排序后再转换成列式输出。

![](https://pica.zhimg.com/80/v2-6987f8d7a617378043b4f216bdd78b80_1440w.webp)

## 二 对关系数据排序

下面是一条OrderBy语句，要点如下：

- SELECT * 表示需要返回customer表的所有列
- ORDER BY c_birth_country ..., c_birth_year... 表示对c_birth_country、c_birth_year两列进行排序，先排c_birth_country，当两行数据的c_birth_country相等时，再排c_birth_year。
- DESC/ASC指出了排序的顺序分别是降序和升序
- NULLS LAST/NULLS FIRST指出了对NULL的处理方式，分别是放在最后和最前
- 用于排序的c_birth_country和c_birth_year两列成为key，customer表的其他输出列称为payload

![](https://pic1.zhimg.com/80/v2-74cf7d2464c2f84e8ab37c6b453e8134_1440w.webp)

可以看出，对关系数据的排序复杂度是远远高于对数组排序的。关系数据排序主要面临下面几个问题：

- Branch问题：因为关系数据排序的Compare很复杂，类似下面代码，需要很多分支判断来实现。过多的分支意味着CPU很难分支预测准确，进而影响排序性能。

```cpp
// 这是简化的代码示意，实际上还需要考虑NULLS FIRST/NULLS LAST，
// 根据c_birth_country和c_birth_year的数据选择不同类型的比较器
// 分支会更多
bool compare(Row left, Row right){
    // 第一列相等，比较第二列
    if(left.c_birth_country == right.c_birth_country){
        if(c_birth_year is ASC){
            return left.c_birth_year < right.c_birth_year;
        }
        else{ // DESC
            return left.c_birth_year > right.c_birth_year;
        }
    }
    // 第一列不等，根据升降序返回大小
    if(c_birth_country is ASC){
        return left.c_birth_country < right.c_birth_country;
    }
    else{ // DESC
        return left.c_birth_country > right.c_birth_country;
    }
}
```

- Cache问题：OLAP通常是列式存储，这意味着在同一行的c_birth_country和c_birth_year在物理上并不连续。c_birth_country相等时，需要取c_birth_year进行比较，这会导致CacheMiss。

- 物理重排问题（又称为：物化 materialize）：OLAP通常是列式存储，但是SQL的排序语义是按行排序（也就是每两行进行比较，第一列相等则比较第二列...），这意味着列式存储需要额外的操作来“隐式”表达成行存，通常两种做法：

- 经典的实现就是通过维护行号将每一列数据关联起来。

- 另外一种做法就是直接将列存物化成行存，对行排序完再转换成列存。本文认为这种做法性能更好。

- payload问题：最终的结果还包括payload列，通常也是两种做法：

- 维护对应的行号，最后根据行号兑值出有序的payload列，劣势是兑值是随机访问，Cache不友好。

- 直接将payload列也物化到行存中，劣势是增加了列转行的开销。本文主要关注对key的排序，没有探究payload的问题。

## 三 探究方法

## 3.1 排序数据集

数据集考虑如下维度：

- 数据分布：

- Random：所有数据随机生成

- Unique128：只有128个数据，均匀分布

- PowerLay：只有128个数据，幂为5的幂率分布，和Unique128很像，但是倾斜严重，少数几个数值大量出现，绝大部分数值出现次数很少。

- 排序列：1~4行

- 数据量：2^10 ~ 2^24行

- 数据格式：行存、列存

## 3.2 实验环境

测试环境如下，主要使用AWS的m5d.8xlarge，Intel芯片。部分场景也会用ARM芯片的m6gd.8xlarge进行对比测试。由于AWS都是虚拟机，由于安全限制，无法采集性能参数（比如CacheMiss、BranchMiss），所有性能数据通过MacBook进行收集。

![](https://pic3.zhimg.com/80/v2-a26000c6674aa3b3173b92746a6e67ec_1440w.webp)

## 四 行存（NSM）和列存（DSM）

两种存储方式

- 行存：同一行的数据在内存上连续存储
- 列存：同一列的数据在内存上连续存储

两种排序方式：

- tuple-at-a-time（逐行排序）：每一次比较决定出两行数据的大小关系，先比第一列，如果相等再比第二列，直到比较出大小，或者比完所有排序列。
- subsort（逐列排序）：首先比较第一列数据，如果有相等的数据，抽出相等数据的范围（称为range或者ties），针对这些等值范围在第二列进行排序，直到完成所有排序列的比较

两种排序方式和两种数据格式（行存和列存）可以互相组合，一共有四种情况，论文将对这四种情况进行了测试。

## 4.1 列存排序

### 4.1.1 理论分析

### 4.1.1.1 列存的逐行排序

列存数据排序都是对行号（row_id）排序，最后根据行号物化出最终的有序结果。逐行排序的一次比较决定两行数据的大小。排序逻辑简要表示（不考虑NULL，DESC，数据类型...）如下：

```cpp
// 用于比较两行数据的大小
bool compare(l_id, r_id, cols) {
	size_t i = 0;
    // 逐列进行判断，第一列相等，则比较第二列...
	for (; i < cols.size() - 1; i++) {
        // l_id和r_id是row_id，需要先兑值出真实值再比较
		if (cols[i][l_id] != cols[i][r_id])
		break;
	}
	return cols[i][l_id] < cols[i][r_id];
}

// 对idxs进行排序，而不是具体的数值
std::sort(idxs, idxs + N, [&] (l_id, r_id) -> bool {
	return compare(l_id, r_id, cols);
}
);
```

列存的逐行排序有三大性能问题：

- CacheMiss 1：如果第一列的数据相同，则需要比较第二列，这里会有一次随机访问，因为在列式存储下，第一列中的数据和第二列的数据在内存上不连续。频繁的随机访问会导致严重的CacheMiss进而影响性能。数据集中重复值越多，这个问题会越明显，所以Unique128和PowerLay较之于Random分布CacheMiss会更严重。
- CacheMiss 2：通常的排序算法会Swap真实的数据，随着排序的进行，数据的局部性会逐渐变好，进而降低CacheMiss。但是在列存逐行排序中，每次Swap交换的是row_id，而不是真实的数据，每次根据row_id获取真实值都是一次随机访问，CacheMiss严重
- BranchMiss：比较函数有较多的分支。由于具体走到哪个分支和排序的数据相关，所以CPU很难做到准确的分支预测。相同值较多的数据集会有更多的BranchMiss，因为第一列相等还需要比较第二列，会走到更多的分支，分支预测失败的可能性更大。

### 4.1.1.2 列存的逐列排序

列存数据排序都是对行号（row_id）排序，最后根据行号物化出最终的有序结果。逐列排序每次Swap同时交换原始数据和row_id。如果有相同值范围，使用对应的row_id取出下一列的数据，继续进行排序。

列存逐列排序可以解决列存逐行排序的三个问题：

- 解决CacheMiss 1：列排一次处理一列数据，不涉及到跨列处理，访存更聚集，CacheMiss更少。
- 解决CacheMiss 2：因为Swap也会交换原始数据，可以拿到原始数据逐渐聚集的访存收益。虽然，对重复值的下一列排序时，依然要使用row_id从下一列取值（随机访问），但是较之于逐行排序每一次取值都要随机访问已经好很多了。
- 解决BranchMiss：在Compare函数中，只需要简单比较两个值的大小，不像逐行排序的Compare中需要大量的分支判断。所以，可以有效减少BranchMiss。

综上，对于列存数据，逐列排序较之于逐行排序性能更好。

### 4.1.2 实验测试

### 4.1.2.1 性能数据

性能数据（Performce Counter）通常由perf命令获取，可以详细查看一段代码的CacheMiss和BranchMiss次数。

结果如下图，C（Column）表示列存，T（Tuple-at-a-time）表示逐行排序，S（Subsort）表示逐列排序。可以看到，和前面的理论分析基本一致，在列存场景下，逐列排序的CacheMiss和BranchMiss都更少。

比较特殊的是Random数据集，逐行排序和逐列排序的CacheMiss和BranchMiss相差不大。随机数据意味着，在逐行排序时，大概率第一列比较就可以比较出大小，不用再比较第二列数据。进而不需要根据row_id随机访问第二列数据，减少了CacheMiss，也不需要执行后面列的判断分支，减少了CacheMiss。

![](https://pic1.zhimg.com/80/v2-a38aa3944bca75d5a6d92dd183785950_1440w.webp)

### 4.1.2.2 benchmark测试

下图是列存的两种排序方式的benchmark测试结果，每一个的数据是逐列排序较之于逐行排序的相对值，值越大表示性能越好。

可以看出，无论是排序列多少，数据量多少，数据分布如何，在列存场景下，逐列排序**全面优于**逐行排序。

此外还有两点需要注意：

- 单列场景下，行排和列排的性能差距不大。这是因为逐行排序也只是比较第一列的数据就出结果，不涉及后面列的比较，没有前文提到的CacheMiss和BranchMiss问题。
- Random分布下，行排和列排的性能差距不大。类似的，由于数据完全是随机的，基本上比较第一列就可以出结果，不用比较后面的列，逐行排序不会遇到前文提到的CacheMiss和BranchMiss问题。

![](https://pic4.zhimg.com/80/v2-708e3e9e5d4e1c894ef612e3340db273_1440w.webp)

## 4.2 行存排序

### 4.2.1 实验测试

### 4.2.1.1 性能数据

结果如下图，R（Row）表示行存，T（Tuple-at-a-time）表示逐行排序，S（Subsort）表示逐列排序。有如下结论：

- 和列存做横向对比，无论是CacheMiss还是BranchMiss，**行存的两种排序方法都有量级上的提升**。
- 行存逐列排序的BranchMiss表现更好，原因和前文所述一样，一次Compare中涉及的分支判断少。
- 行存场景下，列排和行排的CacheMiss相差不大。列排的CacheMiss会稍微多一些，这是因为列排在排后面列需要使用row_id兑值，是随机访问。

![](https://pic3.zhimg.com/80/v2-bf83a737bf86f0763ca29d47632f9f50_1440w.webp)

### 4.2.1.2 benchmark测试

这里的benchmark测试是想说明行存的性能优于列存。

下图是以最好的列存排序（也就是列存逐列排序，前面的理论分析和 实验说明了列存逐列排序优于列存逐行排序）为基线的相对性能结果，值越大表示性能越好。可以得出如下结论：

- 无论是行存的逐行排序还是行存的逐列排序，性能都优于列存排序。
- 当数据量较小时，行存列存排序的性能差异不大，因为数据可以兜在Cache中，随机访问并不会造成CacheMiss

![](https://picx.zhimg.com/80/v2-0262ef611616aa06f125545fbaae9ad1_1440w.webp)

综上，行存排序（tuple-at-a-time和subsort）全面优于列存排序，且数据量越大，性能优势更大。但是，通常的OLAP数据库都是列存的，如果要使用行存，需要先将列式数据转换成行式数据，排序后再将行式数据转换成列数数据传递给下一个算子。排序前后的行列转换是额外的开销。一个自然而然的**问题**是：在列存场景下，行列转换配合行存排序的性能和直接使用列存排序，那种方案的性能更好。

## 4.3 不同执行方式的真实运用

行存/列存 ✖️ 逐行排序/逐列排序 一共有4种组合，这并不是作者“强行”构造的场景。实际上，除了“行存-逐列排序”之外，业界都有相应的运用。

|   |   |   |
|---|---|---|
||逐行排序（符合OrderBy语义）|逐列排序|
|行存|DuckDB，Velox|-|
|列存（有利于性能，OLAP）|Presto|ClickHouse的多列场景|

## 五 执行引擎对排序的影响

Volcano模型使用tuple-at-a-time的解释执行方式，有严重解释执行开销。OLAP系统为了解决这个问题，有两大流派：

- 向量化执行引擎：也是解释执行模型，不同的是一次解释执行一个向量数据（一批数据），一次解释执行的开销均摊到一批数据的每一个上面就很小了。
- 代码生成执行引擎：通过及时代码生成（JIT [just-in-time](https://zhida.zhihu.com/search?q=just-in-time&zhida_source=entity&is_preview=1)）技术，在执行过程中动态生成代码。由于在执行的时候，完全知道此次排序列的类型、升降序、NULL FIRST/LAST等信息，基本上可以完全消除解释代价。

向量化和代码生成都是优化性能的方法，且可以同时使用，但是通常的OLAP系统只选择其中一种作为自己的执行方式。

## 5.1 代码生成排序

这篇论文直接给出了测试结论，在其benchmark中，使用代码生成的性能最好。这和[《MonetDB/X100 - A DBMS In The CPU Cache》](https://link.zhihu.com/?target=https%3A//ir.cwi.nl/pub/11098/11098B.pdf)这篇论文的提到的结论一致。如下图，最左下角的Hand-Coded性能是最好好的，其他三个区域表示向量化实现在不同向量大小下的性能，都没有生成代码好。

![](https://pic1.zhimg.com/80/v2-8a04b37532bede316c941ef78da25ff2_1440w.webp)

这里拓展一下，《A DBMS In The CPU Cache》是向量化执行引擎重要的奠基文章，依然承认代码生成的性能更好，这是不是说明代码生成全面优于向量化实现呢？答案是否定的，原因如下：

- 无论是这篇论文还是《A DBMS In The CPU Cache》，给出的都是“手写”的测试代码性能，通常可以把相关代码优化到极致。在真实的场景中，使用“代码”来即时生成优化代码，性能通常没有手写代码性能好。
- 在真实场景中，代码生成较之于向量化逻辑晦涩很多，且没有很好的debug手段，开发和维护成本极高。

依据上述原因，现在业界的主流优化方向是向量化，在向量化无法很好解决性能问题的时候，才考虑做轻量级的代码生成。很多原本基于代码生成的执行引擎正在往向量化引擎转变，比如Presto -> Velox，Spark -> Photon。这篇文章落地的数据库DuckDB也是一个很好的例子，DuckDB主要采用向量化引擎。

## 5.2 向量化排序

前文提到过，向量化排序（subsort、逐列排序）的CacheMiss更严重，当数据量较大时，性能表现不好。除此之外，向量化排序的应用场景有限，比如不能用于Merge逻辑，因为Merge每出一条数据，需要比较两行的所有列。

综上，似乎逐行排序是更优解，但是逐行排序也有问题。在逐行排序中，每比较两行数据，都需要多次根据数据类型、ASC/DESC、NULLS FIRST/LAST走不同的分支（这称为解释执行开销）。而向量化排序中，处理一批数据只有一次解释开销，这是向量化排序的**优点**。

在技术选型前，需要回答一个问题：逐行排序多出来的解释执行开销到底有多大？如果开销小，直接选择逐行排序；如果开销大，则考虑逐列排序，或者进一步优化逐行排序。

为了解答这个问题，这篇论文做了相应的实验进行验证，对Compare基本函数做了两套实现：

- 使用动态函数调用，在运行时根据排序列的类型、ASC/DESC...走不同的逻辑，模拟出解释执行开销
- 使用静态函数调用，根据排序列的类型、ASC/DESC...在编译前把逻辑固化下来，完全消除了解释开销。

实验结果如下，采用动态函数调用的全部慢于静态函数调用，而且相对性能差异大。这意味着解释执行开销很大，不容忽视。

![](https://pic4.zhimg.com/80/v2-3c4372052b0a57c025258320c31dcc95_1440w.webp)

所以，逐行排序的解释执行开销是不能忽略的。又由于逐列排序的固有问题（详见4.2, 列存排序性能低于行存），这篇论文选择了在逐行排序的基础上进行优化，尽可能消除掉逐行排序的解释执行开销。

## 六 DuckDB的四板斧

论文在本章之前，通过大量的理论分析和实验，总结出了排序的基本范式，和各种排序范式的优劣。并得出一些基本结论：

- 数据结构角度：基于行存的排序全面优于基于列存的排序

- 排序方法角度：逐行排序和逐列排序各有千秋：

- 逐行排序的应用面更广（比如Merge），CacheMiss更少，但是解释执行开销大

- 逐列排序的解释执行开销较小

综合考量下，这篇论文选择了**基于行存**的逐行排序，但是需要解决前面发现的问题，消除劣势，扩大优势。

## 6.1 Normalized Keys

Normalized Keys就是将多个排序列，以某种编码方式，[序列化](https://zhida.zhihu.com/search?q=%E5%BA%8F%E5%88%97%E5%8C%96&zhida_source=entity&is_preview=1)成一个String列，之后直接对序列化后的String列进行排序。

以下图为例，a是排序列的原始数据，b是对应原始数据在内存中的表示，c是序列化的结果。要点如下：

- 对于Varchar类型，需要补“0”使长度对齐。比如第一列的GERMANY较之于NETHERLANDS少了4个字符，用“0”进行补齐。

- 根据ASC/DESC决定是否反转每一个bit位。第一列是DESC，需要将每一bit进行反转，比如：0(0000) -> 255(FFFF)

- 对于数值类型，根据大小端机调整byte顺序。在大端机中，数值的高位byte存储在后面的内存，需要调整到前面。比如第二列的Integer类型："200 7 0 0" -> "0 0 7 200"

- 对于数值类型，需要将符号位进行反转，确保正数大于负数。比如第二列的Integer类型："0 0 7 200" -> "128 0 7 200"

- 在每个数值前额外使用一个byte来表示是否为NULL，具体的值由NULLS FIRST/LAST决定。如果确定非NULL值没有max/min，也可以用最高位bit来表示，而不用一个byte

- 确保每一行的序列化结果长度一样，这样可以在排序的过程中直接Swap两行数据本身，而不是Swap指向两行数据的指针。这样做的好处前文已经论述过，可以随着排序的推进减少CacheMiss。

- 为了达到序列化结果长度一样的目的，对特别长的Varchar在序列化时做截断操作。比较时先比较前缀，如果相等比较后面部分。

- 对序列化后的数据排序，相当于对单列的二进制串进行排序，使用memcpy实现Swap操作，使用memcmp实现Compare操作

![](https://pic3.zhimg.com/80/v2-76ddfa52e772401a1d0a319b40a7f1fc_1440w.webp)

![](https://picx.zhimg.com/80/v2-07eecf527a400bf1336f00b71dc1bbbd_1440w.webp)

序列化过程其实是将列存数据转换成行存的过程，这个过程是有开销的。转化过程本身可以通过“向量化”的方式进行，也就是逐行序列化，可以摊薄序列化本身的解释执行开销。对序列化后的数据进行排序就基本消除了解释执行开销。

## 6.2 动态调用和静态调用

### 6.2.1 概念和方法论

memcpy有两种调用方式

- memcpy(desc, src, size)：论文称这种方式为**动态调用**，因为每次调用需要代码上下文显式给出size参数的值。
- memcpy(desc, src, 具体的数值)：论文称这种方式为**静态调用**，因为拷贝的数据量是写死的。这意味着编译器可以对其做优化，比如：消除传入size参数的压栈逻辑、将用到size参数的[汇编指令](https://zhida.zhihu.com/search?q=%E6%B1%87%E7%BC%96%E6%8C%87%E4%BB%A4&zhida_source=entity&is_preview=1)改写成直接使用具体值......

显然，有更多编译器优化机会的静态调用方式性能会更好，具体可以如下实现：

![](https://pic1.zhimg.com/80/v2-b80c30c0b552da2e0cb9aa9c37ceae94_1440w.webp)

这里有一个**疑问**，虽然用到了静态调用，但是额外引入大量的判断分支，不会造成性能回退么？

答案是**不会**，因为在排序过程中，每次调用s_mecpy进行Swap操作，传入的参数是定值，现代CPU有分支预测功能，只要每次走固定分支，基本上是没有额外开销的。

将热点函数从动态调用转换成静态调用是一种**通用优化**，以一种非常低的改造成本达到了类似于代码生成的优化效果。但这种优化的风险点在于，不同的编译器、CPU架构会导致不同的性能结果，在某些场景下可能导致回退。

### 6.2.2 实验

对数组进行memcmp/memcpy的静态/动态调用性能测试，数组元素的size从0~64byte，分别在x86架构和ARM架构下进行测试，结果如下：

- 图1和图2，对于动态memcpy，无论那种架构都有专门的优化，比如8~15Byte，拷贝的数据量变化了，但是用时没有变化（分阶段的水平线）。
- 图3和图4，对于动态memcmp，当size为8和16的的倍数时，用时会有一个跨度很大的减少。
- 从平均用时上看，x86上的memcmp和memcpy性能表现好于ARM
- 图3，在x86上的静态和动态调用差别不是很大，在size 8~16，静态调用**好于**动态调用。其他情况静态调用性能**更低**
- 图1，在x86上的静态调用性能明显**低于**动态调用
- 图4，在ARM架构上，当size小于16时，memcmp静态调用平均比动态调用**快25%**。其他情况静态调用性能**更差**。
- 图2，在ARM架构上，memcpy静态调用平均比动态调用**快55%**，当size小于16时，平均**快92%**，当size小于8时，平均快**121%**。

综上，将动态调用改成静态调用是否有收益，和CPU架构、处理的内存数据量有关。所以，使用静态调用优化一定要通过实际测试来确保是否有收益。

!\[\[Pasted image 20240905161504.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='902' height='930'></svg>)

## 6.3 Radix Sort

### 6.3.1 QuickSort和RadixSort

|   |   |   |
|---|---|---|
||[时间复杂度](https://zhida.zhihu.com/search?q=%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6&zhida_source=entity&is_preview=1)|额外内存|
|QuickSort|O(NlogN)|O(1)|
|RadixSort|O(kN)|O(N)|

- RadixSort的优点：

- 时间复杂度为O(kN)，k是排序列的size，和数据量无关，当数据量大时有不错的性能收益。

- 此外，采用NormalizedKey优化后，适配RadixSort的代价较小。

- RadixSort的缺点：

- 如果排序列较场，且有很多重复值，或者已经基本有序，RadixSort的每一轮处理效率较低

- RadixSort较之于比较排序Cache效率较低，因为随着比较排序的推进，数据会更聚集。但RadixSort每一轮排序都需要分桶拷贝，随机访问相对较多。

为了尽可能发挥RadixSort的性能，可以做如下优化：

- 算法选择优化：

- 当排序的数据量\<=24行，直接使用插入排序

- 其他数据量使用RadixSort排序：

- 当key size \<= 4 byte，使用LSD（Least Significant Digit）Radix Sort，排序key长度较小LSD性能更好

- 当key size > 4 byte，使用MSD（Most Significant Digit）Radix Sort

- 拷贝优化：

- 减少不必要的拷贝，比如一轮分桶完成后，发现所有的数据都属于一个桶，可以直接跳过这次拷贝

- 使用静态调用的memcpy

### 6.3.2 benchmark测试

使用优化后的RadixSort和pdqSort进行性能比较，pdqSort是目前比较排序的最好实现，分支预测失败较少，并且会识别出quickSort表现不佳数据pattern，并进行规避。结论如下：

- 在Random分布下，RadixSort基本上全面优于pdqSort，且只有一个排序列时性能优势最明显。随机分布意味着Radix每一次分桶都可以有效判断出大小，排序列少，意味着O(kN)中的k小。
- 在Unique128分布下，pdqSort的表现优于RadixSort。当面对大量的重复值时，RadixSort每一轮的分桶的效率低下，进而导致总体效率低。但是pdqSort可以识别出这种数据pattern，有专门的优化，性能表现更好。但是随着排序列的增多，RadixSort逐渐追平或反超pdqSort，因为列数增多，从一整行的角度来看，是Distinct的，这有利于RadixSort。
- PowerLaw分布和Unique128分布有类似的结论，但由于PowerLaw分布的倾斜更严重，pdqSort的相对表现更好。

!\[\[Pasted image 20240905161516.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='908' height='452'></svg>)

### 6.3.3 性能数据

获取RadixSort和pdqSort的CacheMiss和BranchMiss：

- RadixSort的CacheMiss多于pdqSort。因为随着pdqSort排序的推进，数据局部性逐渐变好。
- RadixSort基本没有BranchMiss。在Radix时基于分布的排序，其算法实现中基本没有任何分支判断。
  !\[\[Pasted image 20240905162320.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='878' height='522'></svg>)

## 6.4 高效Merge

如果直接对全量数据进行排序，会有较为严重的CacheMiss。更好的做法是多线程并发排序，如下图所示：每一个线程一次排Cache大小的数据，这样的CacheMiss会很少。最后需要一个Merge逻辑来将多个有序向量合并成一个全局有序的结果。

!\[\[Pasted image 20240905162330.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1796' height='808'></svg>)

Merge也有很大的优化空间，业界通常的做法是采用多路归并，多路归并有很多缺点：

- 比较完所有路才能出一行数据，比较逻辑的分支多，且Cache不友好（每一路的物理内存不连续）
- 通常是单线程实现

DuckDB采用级联的两两归并来实现Merge，性能好好。两两归并，简化了比较逻辑，进而简化了判断分支，同时也从N路归并的每次访问N块不连续内存缩减为2块不连续内存，Cache更友好。级联归并可以尽可能利用多线程提速。

如下图所示，Thread 0和Thread 1可以并行的进行归并。最后一次的归并只能单线程进行。

!\[\[Pasted image 20240905162340.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1284' height='954'></svg>)

我们希望在两两归并时，每一个Merge处理的数据量相等（没有倾斜）。这需要对SortedVector进行合理的切分，让Merge完的结果刚好可以拼接成一个完整的有序结果，如下图所示。找到切分点的算法称为MergePath，MergePath算法会运用[二分查找](https://zhida.zhihu.com/search?q=%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE&zhida_source=entity&is_preview=1)的思路快速定位分割点，详见[《Merge Path - A Visually IntuitiveApproach to Parallel Merging》](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1406.2628)

!\[\[Pasted image 20240905162351.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='2068' height='1106'></svg>)

## 七 端到端测试

如下图，1千万~1亿数据两的Integer和Float排序，DuckDB全面超越竞品排序。

!\[\[Pasted image 20240905162400.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='864' height='524'></svg>)

对TPCH-DS的catalog_sales表排序，数据量由SF参数决定：

!\[\[Pasted image 20240905162407.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='558' height='274'></svg>)

数据量分别为SF10和SF100，排序列为1 ~ 4，DuckDB全面超越竞品排序。

!\[\[Pasted image 20240905162413.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='856' height='532'></svg>)

数据量分别为SF10和SF300，无论是对Integer还是对String排序，DuckDB都属于第一梯队，和Umbra持平。

!\[\[Pasted image 20240905162421.png\]\]

!\[\](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='868' height='534'></svg>)

编辑于 2023-11-07 20:15・IP 属地浙江

\[

数据库

\](https://www.zhihu.com/topic/19552067)

\[

排序

\](https://www.zhihu.com/topic/19572852)

\[

性能

\](https://www.zhihu.com/topic/19576984)

​赞同 157​​4 条评论

​分享

​喜欢​收藏​申请转载

​

赞同 157

​

分享

![](https://picx.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=32738c0c&needBackground=1)

理性发言，友善互动

4 条评论

默认

最新

[![VitualWorld](https://picx.zhimg.com/v2-d9cf8b9846e95791ccafaadd9a4206a3_l.jpg?source=06d4cd63)](https://www.zhihu.com/people/70977f77fac12b9381c7538feb40ed11)

[VitualWorld](https://www.zhihu.com/people/70977f77fac12b9381c7538feb40ed11)

最近在整理各个算子行存和列存的优势，答主这个太细，太赞了。目前我们在大数据场景，当多列情况下，sort算子一般是行存优于列存，但如果单列数据的话，快排性能表现更好。所以我个人觉得在优化sort的时候，应该将行列排序弄成不同策略在不同场景使用。

08-20 · 四川

​回复​喜欢

[![魂魄妖梦](https://picx.zhimg.com/5dd9eb9836ec1f72f2b6177de78b1413_l.jpg?source=06d4cd63)](https://www.zhihu.com/people/b49d91f807ec4fe28aa963f66ca181bb)

[魂魄妖梦](https://www.zhihu.com/people/b49d91f807ec4fe28aa963f66ca181bb)

这是默认数据都在内存里测出来的？

08-08 · 江西

​回复​喜欢

[![zhanglistar](https://picx.zhimg.com/516b02447_l.jpg?source=06d4cd63)](https://www.zhihu.com/people/7ada82e7a52188493591aad4730efc3c)

[zhanglistar](https://www.zhihu.com/people/7ada82e7a52188493591aad4730efc3c)

太细了。

05-20 · 浙江

​回复​喜欢

[![被被被被窝吸住了](https://pic1.zhimg.com/v2-ba1e94827293ff1bab472e4b22c501e1_l.jpg?source=06d4cd63)](https://www.zhihu.com/people/9aef4a30bc7d3a0fdc1d24af3eb334c2)

[被被被被窝吸住了](https://www.zhihu.com/people/9aef4a30bc7d3a0fdc1d24af3eb334c2)

![[赞同]](https://pic2.zhimg.com/v2-419a1a3ed02b7cfadc20af558aabc897.png)沙发

2023-10-31 · 浙江

​回复​喜欢

### 文章被以下专栏收录

\[

![IT](https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b)

\](https://www.zhihu.com/column/c_1705318239930867712)

## \[

IT

\](https://www.zhihu.com/column/c_1705318239930867712)

计算机基础知识、性能优化、数据库优化、OLAP

### 推荐阅读

\[

![一文说清数据库有哪些](https://picx.zhimg.com/v2-c051192bc16a53b09b7f685116315a4d_250x0.jpg?source=172ae18b)

# 一文说清数据库有哪些

shalory

\](https://zhuanlan.zhihu.com/p/540108315)\[

# 数据库分片（Database Sharding)详解

本文由云+社区发表 作者：腾讯云数据库 Introduction 导言任何看到显著增长的应用程序或网站，最终都需要进行扩展，以适应流量的增加。以确保数据安全性和完整性的方式进行扩展，对于数据驱…

腾讯云开发...发表于腾讯云开发...

\](https://zhuanlan.zhihu.com/p/57185574)\[

![2020数据库选型攻略：专用VS多模](https://pica.zhimg.com/v2-e31282836cc60665689795ddc55b1799_250x0.jpg?source=172ae18b)

# 2020数据库选型攻略：专用VS多模

IT168企业级

\](https://zhuanlan.zhihu.com/p/299180936)\[

![漫画 | 数据库设计全过程](https://picx.zhimg.com/v2-1d60939714be8ad3ce081f18f7918c65_250x0.jpg?source=172ae18b)

# 漫画 | 数据库设计全过程

小知

\](https://zhuanlan.zhihu.com/p/56960126)
