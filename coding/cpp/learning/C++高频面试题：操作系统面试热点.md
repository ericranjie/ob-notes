# 

Original 往事敬秋风 深度Linux

 _2024年09月03日 18:03_ _湖南_

操作系统如同计算机系统的指挥官，协调着各种硬件资源和软件任务的运行。在求职竞争激烈的技术领域，掌握操作系统的原理和实践是打开职业大门的关键钥匙之一。接下来，让我们一起面对那些可能在操作系统面试中出现的富有挑战性的问题。

![](http://mmbiz.qpic.cn/mmbiz_png/dkX7hzLPUR0Ao40RncDiakbKx1Dy4uJicoqwn5GZ5r7zSMmpwHdJt32o95wdQmPZrBW038j8oRSSQllpnOUDlmUg/300?wx_fmt=png&wxfrom=19)

**深度Linux**

拥有15年项目开发经验及丰富教学经验，曾就职国内知名企业项目经理，部门负责人等职务。研究领域：Windows&Linux平台C/C++后端开发、Linux系统内核等技术。

191篇原创内容

公众号

## 一、进程与线程

### 1.1什么是进程？进程有哪些状态？

进程是计算机中已运行的程序，是系统进行资源分配和调度的基本单位，是操作系统结构的基础 。

**进程主要有以下几种状态：**

- 创建状态：系统已为其分配了进程控制块（PCB），但进程所需资源尚未分配，进程还未进入主存，即创建工作尚未完成，进程还不能被调度运行。
    
- 就绪状态：进程已分配到除 CPU 以外的所有必要资源，等待获得 CPU。
    
- 执行状态：进程已获得 CPU，程序正在执行。
    
- 阻塞状态：正在执行的进程由于某事件而暂时无法继续执行时，放弃处理机而自行阻塞。比如进程当中调用 wait 函数，会使得进程进入到阻塞状态。
    
- 终止状态：进程到达自然结束点或者因意外被终结，将进入终止状态，进入终止状态的进程不能再执行，但在操作系统中仍然保留着一个记录，其中保存状态码和一些计时统计数据，供其它进程收集。
    

另外，在一些系统中，还可能存在挂起状态等其他状态。挂起状态又分为静止阻塞状态和静止就绪状态。引入挂起状态的原因包括终端用户的请求、父进程请求、负荷调节的需要以及操作系统的需要等。

### 1.2进程和线程的区别是什么？

定义方面

- 进程是计算机中已运行程序的实体，是系统进行资源分配和调度的基本单位。
    
- 线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。
    

**资源分配方面**

- 进程是资源分配的基本单位。每个进程都有独立的地址空间，包括代码段、数据段、堆、栈等。不同进程之间的资源是相互独立的，一个进程不能直接访问另一个进程的内存空间。
    
- 线程是共享进程资源的。线程共享所属进程的地址空间和资源，如代码段、数据段、打开的文件等。这使得线程之间的通信相对容易，但也需要注意资源访问的同步和互斥问题。
    

**并发性方面**

- 进程之间的并发性相对较低。进程切换时需要进行较大的上下文切换，包括保存和恢复进程的地址空间、寄存器状态等，开销较大。
    
- 线程之间的并发性较高。线程切换的开销较小，只需要保存和恢复线程的寄存器状态等少量信息。
    

**系统开销方面**

- 创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，因此操作系统所付出的开销远大于创建或撤销线程时的开销。
    
- 线程的切换速度也比进程的切换速度快得多。
    

**通信方式方面**

- 进程间通信相对复杂，可以通过管道、消息队列、共享内存等方式进行通信。这些通信方式需要操作系统提供额外的支持，并且通信的开销较大。
    
- 线程间通信相对简单，可以直接通过共享内存进行通信，也可以使用互斥锁、条件变量等同步机制来协调线程之间的执行顺序。线程间通信的开销较小，效率较高。
    

### 1.3什么是线程同步？有哪些方法可以实现线程同步？

线程同步是指多个线程之间协调和互相配合，以确保它们按照特定的顺序执行或访问共享资源，从而避免竞态条件和数据不一致等并发问题。

**以下是几种常见的线程同步方法：**

- 互斥锁（Mutex）：通过使用互斥锁，在任意时刻只允许一个线程进入临界区，其他线程需要等待。可以使用互斥锁来保护共享资源的访问，并确保原子性操作。
    
- 信号量（Semaphore）：信号量维护着一个计数器，控制同时可以有多少个线程进入临界区。可以用于限制对共享资源的并发访问数量。
    
- 条件变量（Condition Variable）：条件变量用于在线程之间进行通信和同步。它允许某个线程在满足特定条件之前等待，直到其他线程满足条件后通知它继续执行。
    
- 屏障（Barrier）：屏障用于使一组线程在达到某个点之前全部等待，并在达到该点后同时开始执行。常用于阶段性任务的同步。
    
- 原子操作（Atomic Operation）：原子操作是不可分割的单元操作，能够确保操作过程中不会被中断。原子操作可以用于保护共享变量的访问，避免竞态条件。
    
- 读写锁（Read-Write Lock）：读写锁允许多个线程同时对共享资源进行读操作，但在有写操作时需要独占访问。适用于读频繁、写较少的场景。
    

### 1.4解释一下进程间通信的方式有哪些？

进程间通信（IPC）是指不同进程之间进行数据交换和通信的机制。常见的进程间通信方式包括：

- 管道（Pipe）：管道是最简单的一种进程间通信方式，分为无名管道和有名管道。无名管道用于父子进程或者兄弟进程之间的通信，而有名管道可以在无关联的进程之间进行通信。
    
- 信号（Signal）：通过发送信号来实现进程间通信。一个进程可以向另一个进程发送特定类型的信号，接收到该信号的进程可以采取相应的处理动作。
    
- 共享内存（Shared Memory）：多个进程共享同一块物理内存区域，这样它们就能够直接读写这块内存区域中的数据，从而实现高效的数据交换。
    
- 消息队列（Message Queue）：消息队列提供了一种在不同进程之间传递数据的方式。发送方将消息放入队列中，接收方从队列中读取消息，并且每个消息都有一个类型标识。
    
- 套接字（Socket）：套接字是网络编程中常用的一种IPC方式，它通过网络协议实现了不同主机上进程之间的通讯。
    
- 信号量（Semaphore）：使用计数器来控制对共享资源的访问，用于进程间同步和互斥。
    
- 文件锁（File Lock）：多个进程可以通过文件锁来实现对某个文件或者资源的独占性访问控制。
    

### 1.5什么是死锁？产生死锁的四个必要条件是什么？

死锁是指在并发系统中，两个或多个进程（线程）无限期地等待对方持有的资源，而导致系统无法继续运行的状态。产生死锁的四个必要条件是：

- 互斥条件（Mutual Exclusion）：至少一个资源只能被一个进程占用，即该资源在一段时间内只能供给一个进程使用。
    
- 占有和等待条件（Hold and Wait）：一个进程可以持有一个资源并等待其他进程所占有的资源。
    
- 不可抢占条件（No Preemption）：已经分配给一个进程的资源不能被强制性地剥夺，只能由拥有它的进程显式释放。
    
- 循环等待条件（Circular Wait）：存在一组进程，每个进程都在等待下一个进程所占有的资源。
    

当这四个条件同时满足时，就可能产生死锁。为了避免死锁发生，需要采取相应的死锁预防、避免、检测和解除策略。

### 1.6如何避免死锁的发生？

为了避免死锁的发生，可以采取以下几种策略：

- 破坏互斥条件：将某些资源设计成可并发访问，即多个进程可以同时占用该资源。
    
- 破坏占有和等待条件：实现一种策略，要求进程在开始执行之前一次性获取所需的所有资源，而不是逐个获取。
    
- 破坏不可抢占条件：当一个进程已经占有某些资源时，如果另一个进程请求它所持有的资源，系统可以剥夺该进程所持有的资源，并分配给其他请求者。
    
- 破坏循环等待条件：对系统中的所有资源进行编号，并且规定进程只能按编号顺序请求资源。这样就能消除循环等待。
    

以上方法通常被称为破坏死锁产生的四个必要条件。实际应用中根据具体情况选择合适的策略或组合策略来避免死锁的发生。

### 1.7进程调度算法有哪些？

(1)先来先服务（FCFS）调度算法

原理：按照进程进入就绪队列的先后顺序分配 CPU。先进入就绪队列的进程先被调度执行，直到执行完毕或因某种原因阻塞，才让出 CPU 给下一个进程。

优点：简单公平，实现容易。

缺点：对短作业不利，可能使短作业等待很长时间；也不利于 I/O 型作业，因为 I/O 型作业通常需要等待 I/O 操作完成后才能继续执行，可能导致 CPU 长时间空闲。

(2)短作业优先（SJF）调度算法

原理：优先选择运行时间最短的进程进行调度。可以是预计运行时间最短，也可以是实际运行时间最短（需要先执行完一个作业才能知道实际运行时间）。

优点：可以使平均等待时间、平均周转时间最短。

缺点：难以准确估计作业的运行时间；对长作业不利，可能使长作业长时间得不到执行；未考虑作业的紧迫程度。

(3)高响应比优先调度算法

原理：响应比 =（等待时间 + 要求服务时间）/ 要求服务时间。每次调度时选择响应比最高的进程。等待时间相同时，要求服务时间越短响应比越高，有利于短作业；要求服务时间相同时，等待时间越长响应比越高，避免了长作业长时间得不到执行的情况。

优点：兼顾了短作业和长作业的利益。

缺点：每次调度都需要计算响应比，增加了系统开销。

(4)时间片轮转调度算法

原理：将 CPU 时间划分成固定大小的时间片，每个进程轮流获得一个时间片执行。当时间片用完时，进程让出 CPU，进入就绪队列末尾等待下一次调度。

优点：公平性较好，每个进程都能得到一定的 CPU 时间。

缺点：如果时间片设置不合理，可能导致频繁的进程切换，增加系统开销。

(4)多级反馈队列调度算法

原理：设置多个就绪队列，每个队列的优先级不同，时间片大小也不同。新进程首先进入最高优先级队列，按时间片轮转调度。如果在一个时间片内未执行完，则进入下一级队列。优先级越低的队列，时间片越大。在低优先级队列中的进程在执行过程中，如果有新的高优先级进程进入，可抢占正在执行的低优先级进程的 CPU。

优点：兼顾了短作业和长作业、I/O 型作业和 CPU 型作业的需求；能较好地适应各种类型的进程。

缺点：实现较为复杂。

### 1.8操作系统中进程与线程切换过程?

**进程切换过程：**

- 保存当前进程的上下文：处理器将当前进程的程序计数器、寄存器值等信息保存到该进程的进程控制块（PCB）中。这些信息包括当前指令的地址、通用寄存器的值、栈指针等，它们代表了进程当前的执行状态。将当前进程的页表指针等内存管理相关的信息也进行保存，以便在恢复该进程时能够正确地访问其内存空间。
    
- 选择新的进程：操作系统的调度程序根据一定的调度算法从就绪队列中选择一个新的进程。调度算法可能考虑进程的优先级、等待时间、预计执行时间等因素。
    
- 更新内存管理信息：将新进程的页表指针等内存管理信息加载到内存管理单元中，以便处理器能够正确地访问新进程的内存空间。
    
- 恢复新进程的上下文：从新进程的 PCB 中读取其保存的程序计数器、寄存器值等信息，并将这些信息加载到处理器中。处理器开始执行新进程的指令，从上次中断的地方继续执行。
    

**线程切换过程：**

线程切换通常比进程切换更快，因为线程是在同一个进程的地址空间内执行，它们共享了大部分的资源。

- 保存当前线程的上下文：处理器将当前线程的栈指针、寄存器值等信息保存到该线程的线程控制块（TCB）中。这些信息代表了线程当前的执行状态。
    
- 选择新的线程：通常在同一个进程内的线程之间进行切换，操作系统的调度程序根据一定的调度策略选择一个新的线程。调度策略可能考虑线程的优先级、等待时间等因素。
    
- 恢复新线程的上下文：从新线程的 TCB 中读取其保存的栈指针、寄存器值等信息，并将这些信息加载到处理器中。处理器开始执行新线程的指令，从上次中断的地方继续执行。
    

总的来说，进程切换涉及到更多的资源保存和恢复操作，因为不同的进程拥有独立的地址空间和资源。而线程切换相对较快，因为线程共享了进程的大部分资源，只需要保存和恢复线程自身的执行状态信息。

### 1.9请描述整个系统调用过程?

系统调用是操作系统提供给用户程序的一种接口，它允许用户程序访问操作系统的核心功能。以下是系统调用的一般过程：

**用户程序触发系统调用：**

- 当用户程序需要执行一些只有操作系统才能完成的任务时，如读写文件、创建进程等，它会通过特定的指令或函数调用触发系统调用。
    
- 例如，在 C 语言中，可以使用库函数如`open`、`read`、`write`等来触发对文件操作的系统调用。
    

**参数传递和陷入指令：**

- 用户程序将系统调用所需的参数传递给操作系统。这些参数可以通过寄存器、栈或特定的内存区域传递。
    
- 然后，用户程序执行一条特殊的指令，称为陷入指令（trap instruction），该指令将控制权转移到操作系统。陷入指令会触发一个中断，使处理器进入特权模式，并跳转到预先定义的系统调用处理程序的入口地址。
    

**保存上下文：**

- 操作系统在接收到系统调用后，首先保存当前正在执行的用户程序的上下文。上下文包括程序计数器、寄存器值、栈指针等信息，这些信息将在系统调用完成后用于恢复用户程序的执行。
    
- 操作系统将用户程序的执行状态标记为等待系统调用的返回。
    

**系统调用处理：**

- 操作系统根据系统调用号确定要执行的具体系统调用功能。系统调用号通常是一个整数，它与特定的系统调用功能相对应。
    
- 操作系统执行相应的系统调用处理程序，该程序根据系统调用的参数执行所需的操作。例如，如果是文件读取系统调用，操作系统将从指定的文件中读取数据，并将数据返回给用户程序。
    

**返回结果和恢复上下文：**

- 系统调用处理程序完成后，将结果返回给用户程序。结果可以通过寄存器、栈或特定的内存区域返回。
    
- 操作系统恢复用户程序的上下文，包括恢复程序计数器、寄存器值和栈指针等。
    
- 处理器从特权模式切换回用户模式，用户程序继续从系统调用后的下一条指令开始执行。
    

整个系统调用过程涉及到用户程序和操作系统之间的交互，通过陷入指令和上下文切换，用户程序可以安全地请求操作系统的服务，而操作系统则负责执行相应的操作并将结果返回给用户程序。这种机制确保了系统的安全性和稳定性，同时也为用户程序提供了访问操作系统核心功能的途径。

### 1.10后台进程有什么特点，如果要你设计一个进程是后台进程，需要考虑什么?

运行特点

在后台默默运行，不与用户直接交互。用户通常不会直接感知到后台进程的存在，它可以在不干扰用户正常操作的情况下执行任务。一般持续运行，不随用户当前操作的结束而立即停止。例如，一些系统监控进程、数据同步进程等会在后台持续运行，以确保系统的正常运行或数据的及时更新。

资源使用特点

通常对系统资源的占用相对较低。后台进程需要尽量减少对 CPU、内存和磁盘等资源的占用，以免影响前台用户操作的性能。可能会根据系统负载情况动态调整资源使用。例如，在系统资源紧张时，后台进程可以降低自己的优先级或减少资源占用，以保证关键的前台任务能够顺利执行。

如果要设计一个后台进程，需要考虑以下方面：

**(1)功能设计**

- 明确任务目标：确定后台进程的具体任务和目标。例如，是进行数据备份、系统监控、任务调度还是其他特定的功能。
    
- 任务的触发条件：确定后台进程启动和执行的条件。例如，是在系统启动时自动启动，还是在特定事件发生时启动，或者按照一定的时间间隔周期性执行。
    

**(2)性能优化**

- 资源管理：合理管理资源使用，避免过度占用系统资源。可以采用优化算法、缓存技术等减少资源需求。例如，如果是数据处理后台进程，可以对数据进行分批处理，避免一次性加载大量数据占用过多内存。
    
- 效率优化：优化算法和执行流程，提高后台进程的执行效率。例如，对于频繁执行的任务，可以采用高效的数据结构和算法来减少执行时间。
    

(3)稳定性和可靠性

- 错误处理：设计完善的错误处理机制，确保在出现错误时能够正确处理并记录错误信息，以便后续排查问题。例如，对于可能出现的网络连接错误、文件读取错误等进行针对性的处理。
    
- 异常恢复：考虑在出现异常情况时如何恢复后台进程的正常运行。例如，如果后台进程因为某种原因崩溃，是否能够自动重新启动。
    

**(4)与其他进程的交互**

- 通信机制：如果后台进程需要与其他进程进行通信，需要设计合适的通信机制。例如，可以使用消息队列、共享内存、管道等方式进行进程间通信。
    
- 同步与互斥：如果多个进程可能同时访问共享资源，需要设计同步和互斥机制，以确保数据的一致性和完整性。例如，使用锁、信号量等机制来控制对共享资源的访问。
    

**(5)监控和管理**

- 状态监控：提供一种方式可以监控后台进程的运行状态，以便及时发现问题。例如，可以通过日志记录、系统监控工具等方式了解后台进程的运行情况。
    
- 管理接口：如果需要，提供一种管理接口可以对后台进程进行控制，例如启动、停止、配置参数等。这样可以方便系统管理员对后台进程进行管理和维护。
    

### 1.11操作系统中进程调度策略有哪几种?

- 来先服务（FCFS）：按照进程到达的顺序进行调度，即先到达的进程先执行。
    
- 短作业优先（SJF）：选择估计运行时间最短的进程先执行。
    
- 优先级调度：每个进程都有一个与之相关联的优先级，具有最高优先级的进程首先执行。
    
- 轮转调度（Round Robin）：每个进程被分配一个时间片，在时间片用完后切换到下一个就绪队列中的进程，确保每个进程都有机会执行。
    
- 最高响应比优先（HRRN）：根据等待时间和估计运行时间的比值来决定优先级，等待时间越长、估计运行时间越短的进程具有更高的响应比，优先级较高。
    
- 多级反馈队列调度：将就绪队列分成多个优先级不同的队列，每个队列采用不同的调度算法，如轮转或优先级。新来的进程首先插入最高优先级队列，并在当前队列中使用一定时间后降低优先级，以实现更公平的调度。
    
- 带权轮转调度（WRR）：类似于轮转调度，但给不同进程分配不同的时间片大小，根据优先级来确定时间片的大小。
    

### 1.12CAS是一种什么样的同步机制?

AS（Compare and Swap）即比较并交换，是一种无锁的同步机制。

**工作原理**

CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值（B）。当且仅当预期原值 A 和内存位置 V 中的值相同时，才会将内存位置 V 的值修改为新值 B，否则不做任何操作。这个过程是原子性的，也就是说，在执行 CAS 操作时，不会被其他线程中断。

例如，一个线程想要将变量 X 的值从 5 改为 10。它首先读取变量 X 的当前值，假设为 5，这就是预期原值 A。然后，它尝试将变量 X 的值改为 10，即新值 B。在进行修改时，会再次检查变量 X 的当前值是否仍然为 5。如果是，就将其修改为 10；如果不是，说明在读取和修改之间，变量 X 的值被其他线程修改了，那么本次操作失败，这个线程可以选择重新尝试。

**优点**

非阻塞性：与传统的锁机制不同，CAS 不会导致线程阻塞。当多个线程同时尝试更新一个共享变量时，只有一个线程能够成功，其他线程不会被挂起，而是可以继续尝试。这大大提高了系统的并发性和响应性。

高效性：由于避免了线程的阻塞和唤醒，CAS 操作通常比使用锁的同步机制更加高效。它减少了上下文切换的开销，提高了 CPU 的利用率。

**缺点**

ABA 问题：这是 CAS 操作的一个潜在问题。如果一个值从 A 变为 B，然后又变回 A，那么使用 CAS 操作时可能会误认为这个值没有被修改过。为了解决这个问题，可以使用带有版本号的原子变量，每次修改时版本号递增，这样就可以区分出是否发生了 ABA 问题。

循环开销：如果多个线程同时竞争一个共享变量，可能会导致某个线程不断地进行 CAS 操作，却一直失败。这会消耗大量的 CPU 资源，造成所谓的 “忙等” 现象。为了减少这种循环开销，可以采用一些优化策略，如增加延迟、使用自适应的自旋锁等。

应用场景：CAS 在多线程环境下被广泛应用于实现原子操作，如 Java 中的AtomicInteger、AtomicReference等原子类就是基于 CAS 实现的。它适用于对性能要求较高、竞争不激烈的场景，例如计数器、状态标志等的更新操作。

### 1.13CPU是怎么执行指令的?

**取指令**

程序计数器（Program Counter，PC）指向内存中的下一条要执行的指令地址。CPU 根据程序计数器的值从内存中读取指令。

指令从内存被读取到 CPU 的指令寄存器（Instruction Register，IR）中。指令通常包括操作码（opcode）和操作数（operand）两部分。操作码指示要执行的操作类型，操作数则提供操作所需的数据或地址。

**指令译码**

- CPU 中的指令译码器（Instruction Decoder）对指令寄存器中的指令进行译码。译码过程将操作码转换为特定的控制信号，这些控制信号将用于控制后续的操作执行。
    
- 确定指令的操作类型和所需的操作数来源。例如，如果是加法指令，译码器将确定需要从哪些寄存器或内存位置获取操作数，并生成相应的控制信号来执行加法操作。
    

**执行指令**

- 根据译码阶段生成的控制信号，CPU 执行指令所指定的操作。这可能包括算术运算（如加法、减法、乘法等）、逻辑运算（与、或、非等）、数据传输（从内存读取数据到寄存器，或将寄存器中的数据写入内存）等。
    
- 如果指令涉及到操作数，CPU 将从相应的寄存器、内存或其他数据源获取操作数，并将操作结果存储在指定的寄存器或内存位置。
    
- 对于一些复杂的指令，可能需要多个时钟周期才能完成执行。例如，乘法指令可能需要多个时钟周期来进行乘法运算和结果存储。
    

**访存（如果需要）**

- 如果指令需要访问内存，CPU 将根据指令中的地址信息从内存中读取数据或写入数据。例如，加载指令将从内存中读取数据到寄存器，存储指令将把寄存器中的数据写入内存。
    
- 内存访问通常需要一定的时间，这取决于内存的访问速度和系统的架构。在等待内存访问完成的过程中，CPU 可能会暂停执行其他指令，或者使用流水线技术来继续执行后续指令，以提高性能。
    

**写回结果**

- 将执行指令的结果写回到相应的寄存器或内存位置。如果是算术运算指令，结果将被写回到目的寄存器中；如果是存储指令，结果将被写入内存。
    
- 更新程序计数器，使其指向下一条要执行的指令地址。程序计数器的更新方式取决于指令的类型和执行结果。例如，对于顺序执行的指令，程序计数器将自动增加，指向下一条指令的地址；对于跳转指令，程序计数器将被设置为跳转目标地址。
    

**中断处理（如果发生中断）**

- 在指令执行过程中，如果发生中断，CPU 将暂停当前指令的执行，保存当前的执行状态（包括程序计数器、寄存器值等）。
    
- CPU 将根据中断类型确定中断服务程序的入口地址，并跳转到中断服务程序执行。中断服务程序将处理中断事件，例如处理设备请求、错误处理等。
    
- 中断处理完成后，CPU 将恢复之前保存的执行状态，继续执行被中断的指令。
    

### 1.14什么是上下文切换？它会带来什么开销？

上下文切换是指在多任务操作系统中，由于CPU时间片轮转、中断处理或进程阻塞等原因，当前正在执行的进程需要暂停执行，保存当前进程的上下文信息（如程序计数器、寄存器值、内存映像等），然后加载并恢复下一个要执行的进程的上下文信息，使得该进程能够继续执行。

**上下文切换会带来一些开销，包括以下方面：**

- 时间开销：上下文切换本身需要一定的时间来保存和恢复进程的状态信息，而这个过程可能涉及到访问内核数据结构和进行I/O操作，消耗较多的CPU周期。
    
- 资源开销：在进行上下文切换时，需要保存和恢复大量的进程状态信息，包括寄存器内容、内存映像等。这将占用额外的内存空间，并增加了对内存带宽和缓存的需求。
    
- 竞争开销：当有多个进程竞争CPU资源时，频繁发生上下文切换会导致CPU资源被浪费在切换过程中，而不是真正有效地执行任务。这可能导致系统整体性能降低。
    
- 缓存失效：由于不同进程之间的工作集不同，在进行上下文切换时，CPU缓存中的数据可能会失效，导致缓存未命中，进而增加了内存访问的开销。
    

### 1.15解释一下线程的生命周期。

线程的生命周期可以分为以下几个主要阶段：

**新建（New）状态**

当一个线程对象被创建时，它处于新建状态。在这个阶段，线程对象已经被分配了内存空间，但还没有开始执行。例如：

```
Thread thread = new Thread(() -> System.out.println("New thread"));
```

此时，线程`thread`就处于新建状态。

**就绪（Runnable）状态**

当调用线程的start()方法后，线程进入就绪状态。在这个阶段，线程已经准备好被调度执行，但还没有获得 CPU 时间片。处于就绪状态的线程会被放入就绪队列中，等待操作系统的调度。例如：

```
thread.start();
```

调用`start()`方法后，线程`thread`进入就绪状态。

**运行（Running）状态**

当操作系统从就绪队列中选择一个线程并分配 CPU 时间片时，该线程进入运行状态。在这个阶段，线程正在执行其任务。例如，线程正在执行`run()`方法中的代码。

**阻塞（Blocked）状态**

线程在执行过程中可能会进入阻塞状态，原因有多种：

- 等待获取锁：当一个线程试图进入一个同步代码块，但该代码块被其他线程占用时，它会进入阻塞状态，等待获取锁。
    
- 等待 IO 操作完成：当线程进行输入 / 输出操作（如读取文件、网络通信等）时，如果操作尚未完成，线程会进入阻塞状态，等待操作完成。
    
- 等待其他线程的通知：当一个线程调用wait()方法时，它会进入阻塞状态，等待其他线程调用notify()或notifyAll()方法来唤醒它。
    

例如：

```
synchronized (obj) {    // 等待获取锁，进入阻塞状态}// 等待 IO 操作完成InputStream inputStream = new FileInputStream("file.txt");inputStream.read();// 等待其他线程的通知Object lock = new Object();synchronized (lock) {    lock.wait();}
```

**死亡（Dead）状态**

线程进入死亡状态有以下几种情况：

- 线程的任务执行完毕，正常退出。
    
- 线程抛出了未捕获的异常，导致线程终止。
    

例如：

```
Thread thread = new Thread(() -> {    System.out.println("Thread is running.");    // 任务执行完毕，线程进入死亡状态});thread.start();
```

或者：

```
Thread thread = new Thread(() -> {    throw new RuntimeException();    // 抛出未捕获的异常，线程进入死亡状态});thread.start();
```

## 二、内存管理

### 2.1什么是虚拟内存？它的作用是什么？

虚拟内存是计算机系统内存管理的一种技术。它通过将一部分硬盘空间模拟成内存来使用，为每个进程提供了一个连续的、较大的地址空间，这个地址空间独立于实际的物理内存。  
  
工作原理  
  
当程序运行时，操作系统会将程序的一部分代码和数据加载到物理内存中。如果程序需要访问的地址不在物理内存中，就会触发一个缺页中断。操作系统会将所需的页面从硬盘（虚拟内存的存储位置）加载到物理内存中，并更新页表，使程序能够继续执行。同时，操作系统可能会将一些暂时不使用的页面从物理内存中换出到硬盘上，以释放物理内存空间供其他程序使用。  
  
**作用**

- 扩大内存容量：物理内存的容量是有限的，而虚拟内存可以利用硬盘空间来模拟更大的内存空间。这使得计算机能够运行更大的程序和处理更多的数据，而不受物理内存容量的限制。例如，一个需要大量内存的图形处理软件可以在物理内存较小的计算机上运行，因为虚拟内存可以提供额外的内存空间。
    
- 实现内存隔离：每个进程都有自己独立的虚拟地址空间，这使得不同进程之间的内存相互隔离。一个进程不能直接访问另一个进程的内存空间，从而提高了系统的安全性和稳定性。例如，一个进程中的错误不会影响到其他进程的运行，因为它们的内存空间是独立的。
    
- 便于内存管理：虚拟内存使得操作系统能够更方便地管理内存。操作系统可以根据需要将页面从物理内存换出到硬盘上，或者从硬盘加载到物理内存中，从而实现内存的动态分配和回收。例如，当系统内存紧张时，操作系统可以将一些不常用的页面换出到硬盘上，以释放内存空间供其他程序使用。
    
- 支持多任务：虚拟内存为多任务操作系统提供了必要的支持。每个进程都有自己独立的虚拟地址空间，使得多个进程可以同时运行，而不会相互干扰。例如，在一个多任务操作系统中，多个程序可以同时运行，每个程序都有自己的虚拟内存空间，操作系统可以根据需要在不同的进程之间切换，实现多任务的并发执行。
    

### 2.2内存分配方式有哪些？

静态分配

定义：在程序编译或链接时确定所需内存空间的大小，并在程序运行前一次性分配所需的全部内存空间。

特点：

- 分配时间早：在程序运行前就完成了内存分配。
    
- 空间固定：一旦分配，内存空间大小不能改变。
    
- 简单直观：易于理解和实现，因为内存的分配和使用在程序运行前就已经确定。
    

应用场景：适用于程序所需内存空间大小在编译时就可以确定的情况，例如一些小型的嵌入式系统或者特定的算法实现，其中数据结构的大小是固定的。

栈式分配

定义：也称为自动变量分配。当函数被调用时，在栈上为函数的局部变量和参数分配内存空间；当函数返回时，这些内存空间自动被释放。

特点：

- 后进先出（LIFO）：内存的分配和释放遵循栈的后进先出原则，保证了内存的自动管理，减少了内存泄漏的风险。
    
- 快速分配和释放：由于栈的操作通常是高效的，栈式分配可以快速地为局部变量分配内存，并在函数返回时迅速释放内存。
    
- 空间有限：栈的大小通常是有限的，一般由操作系统或编译器设定。如果函数调用层次过深或局部变量占用空间过大，可能会导致栈溢出。
    

应用场景：适用于函数内部的局部变量和参数的分配，这些变量的生命周期与函数的执行周期相对应，函数返回后它们不再被需要。

堆式分配

定义：也称为动态内存分配。程序在运行时根据需要向操作系统请求分配内存空间，使用完毕后由程序员手动释放或者由垃圾回收机制自动回收。

特点：

- 灵活分配：可以在程序运行的任何时候根据实际需求分配不同大小的内存空间。
    
- 手动管理或自动回收：程序员需要负责手动释放不再使用的内存空间，否则可能会导致内存泄漏；或者使用具有垃圾回收机制的编程语言，由垃圾回收器自动回收不再使用的内存。
    
- 空间较大：堆的空间通常比栈大，可以满足程序对较大内存空间的需求。
    

应用场景：适用于程序中动态创建的数据结构，如链表、树、图等，以及需要在运行时动态确定大小的数组等。例如，在一个图形绘制程序中，可能需要根据用户的操作动态分配内存来存储图形对象。

### 2.3什么是内存泄漏？如何检测和避免内存泄漏？

内存泄漏是指由于程序中某些已动态分配的内存没有被正确释放，导致这些内存一直被占用，无法被其他程序或系统重新使用的现象。随着程序的运行，内存泄漏会逐渐积累，最终可能导致系统内存耗尽，影响程序的性能甚至使程序崩溃。

例如，在使用 C 或 C++ 等编程语言时，如果使用`malloc`或`new`分配了内存，但在不再需要时没有使用`free`或`delete`释放内存，就可能发生内存泄漏。

**内存泄漏的检测方法**

**静态代码分析工具**

许多静态代码分析工具可以检测潜在的内存泄漏问题。这些工具通过分析源代码，查找可能导致内存泄漏的模式，如未释放的内存分配、资源未正确关闭等。

例如，在 C 和 C++ 开发中，可以使用工具如 Valgrind、Cppcheck 等。Valgrind 可以检测各种内存错误，包括内存泄漏、非法内存访问等。它通过模拟程序的执行，跟踪内存的分配和释放情况，在程序运行结束后报告是否存在内存泄漏以及泄漏的位置。

**动态内存分析工具**

动态内存分析工具在程序运行时监控内存的使用情况，可以检测到实际发生的内存泄漏。

例如，在 Java 开发中，可以使用工具如 JProfiler、YourKit 等。这些工具可以跟踪对象的分配和释放，识别哪些对象被创建但没有被及时释放，从而帮助开发人员定位内存泄漏的位置。

**代码审查**

人工进行代码审查也是检测内存泄漏的一种有效方法。开发人员可以仔细检查代码中对动态内存的分配和释放情况，确保所有分配的内存都在适当的时候被释放。

特别是在处理复杂的程序逻辑或使用多个资源的情况下，代码审查可以帮助发现潜在的内存泄漏问题。

**避免内存泄漏的方法**

正确管理内存分配和释放

在使用需要手动管理内存的编程语言（如 C 和 C++）时，确保在不再需要内存时及时释放。使用free或delete释放动态分配的内存，并注意内存分配和释放的配对。

例如：

```
     std::unique_ptr<int> ptr(new int);     // 不需要手动释放，智能指针会自动处理
```

在使用具有自动内存管理机制的编程语言（如 Java、Python 等）时，虽然不需要手动释放内存，但仍要注意避免创建不必要的对象，以减少内存的消耗。

**使用资源管理类**

在 C++ 中，可以使用智能指针（如std::unique_ptr和std::shared_ptr）来自动管理内存的分配和释放。智能指针在对象不再被使用时自动释放所管理的内存，避免了手动释放内存的错误。

例如：

```
     std::unique_ptr<int> ptr(new int);     // 不需要手动释放，智能指针会自动处理
```

在 Java 中，可以使用`try-with-resources`语句来自动关闭资源，避免资源泄漏。例如，对于文件输入流，可以这样使用：

```
     try (BufferedReader reader = new BufferedReader(new FileReader("file.txt"))) {         // 使用 reader     } catch (IOException e) {         e.printStackTrace();     }
```

**避免循环引用**

在一些编程语言中，如 JavaScript 和某些面向对象的编程语言中，可能会出现循环引用的情况，导致对象无法被垃圾回收。

例如，在 JavaScript 中，如果两个对象相互引用，并且没有其他对象引用它们，它们将不会被垃圾回收器回收。为了避免这种情况，可以在适当的时候手动断开循环引用，或者使用弱引用（在支持弱引用的语言中）。

及时清理不再使用的对象

在程序中，如果一个对象不再被使用，应尽快将其设置为null或从引用列表中移除，以便垃圾回收器能够回收其占用的内存。

例如，在 Java 中，如果一个集合中存储了不再需要的对象，可以将其从集合中移除：

```
     List<Object> list = new ArrayList<>();     Object obj = new Object();     list.add(obj);     // 不再需要 obj     list.remove(obj);     obj = null;
```

### 2.4解释一下内存碎片的产生原因及解决方法。

**内存碎片的产生原因**

动态分配和释放内存：当程序频繁地进行动态内存分配和释放时，会导致内存空间被分割成许多不连续的小块。例如，在 C 或 C++ 中使用`malloc`和`free`函数，或者在 Java 等语言中频繁创建和销毁对象，都可能引起这种情况。

假设一个程序先分配了一块较大的内存，然后释放了一部分，接着又分配了一些较小的内存块。此时，原本连的内存空间就被分割成了不同大小的碎片。

内存分配策略：不同的内存分配算法也可能导致内存碎片的产生。例如，首次适应算法（First Fit）会从内存的起始位置开始查找第一个满足需求的空闲块进行分配，这可能会使后面的较大内存请求难以找到连续的空间，从而产生碎片。

最佳适应算法（Best Fit）会选择与请求大小最接近的空闲块进行分配，虽然可以尽量减少浪费的空间，但会使内存中留下许多小的空闲块，加剧碎片问题。

程序的运行时间和内存使用模式：如果程序长时间运行，并且内存的使用模式不断变化，也容易产生内存碎片。例如，一个服务器程序在长时间运行过程中，不断地接收不同大小的请求，进行内存分配和释放，随着时间的推移，内存碎片可能会越来越多。

**内存池技术**

内存池是一种预先分配一定大小的内存空间，供程序在运行时使用的技术。程序在需要内存时，从内存池中获取，而不是直接进行动态分配。当不再需要内存时，将其归还给内存池，而不是释放给操作系统。

这样可以避免频繁的动态分配和释放，减少内存碎片的产生。例如，在 C++ 中，可以实现自己的内存池类，管理特定大小的内存块，提高内存分配和释放的效率。

**压缩和整理内存**

- 定期对内存进行压缩和整理，将分散的空闲内存块合并成较大的连续空间。这种方法通常需要暂停程序的执行，以便进行内存的重新组织。
    
- 在一些编程语言的垃圾回收器中，会采用类似的技术。例如，Java 的垃圾回收器在进行垃圾回收时，可能会对堆内存进行压缩，以减少碎片。
    

**优化内存分配策略**

选择合适的内存分配算法可以减少碎片的产生。例如，伙伴系统（Buddy System）是一种有效的内存分配算法，它将内存分成不同大小的块，并通过合并相邻的空闲块来减少碎片。

另外，可以采用 slab 分配器等技术，针对特定大小的对象进行优化分配，减少内存碎片。

**限制内存分配和释放的频率**

- 在程序设计中，可以尽量减少不必要的内存分配和释放操作。例如，对于一些可以重复使用的对象，可以进行缓存，避免频繁地创建和销毁。
    
- 如果可能的话，可以在程序启动时一次性分配所需的大部分内存，然后在运行过程中根据实际情况进行少量的调整，而不是频繁地进行动态分配。
    

### 2.5用户态和核心态的区别?

用户态和核心态是操作系统中的两种不同的运行模式，它们主要有以下区别：  
  
**权限级别**

用户态：权限较低。在用户态下运行的程序只能访问受限的资源，不能直接访问操作系统的核心数据和硬件设备。例如，用户态的程序不能直接访问内存的物理地址、不能直接控制硬件设备（如硬盘、网卡等）。

核心态：权限高。处于核心态的操作系统内核可以访问系统的所有资源，包括硬件设备、内存的物理地址等。它负责管理和控制整个系统的运行，如进行进程调度、内存管理、设备驱动等关键任务。

**运行环境**

用户态：运行在用户空间。这是为应用程序提供的运行环境，每个应用程序都有自己独立的用户空间。用户态程序的运行环境相对简单，主要包括用户程序的代码、数据和栈等。

核心态：运行在内核空间。内核空间是操作系统内核运行的区域，它包含了操作系统的核心代码和数据结构。内核态程序的运行环境更加复杂，需要处理各种系统级的任务和异常情况。

**切换方式**

用户态到核心态：通常是通过系统调用、中断或异常来触发。例如，当应用程序需要读取文件时，它会通过系统调用进入核心态，由操作系统内核来执行文件读取操作。当硬件设备产生中断时，处理器会从用户态切换到核心态，由操作系统内核来处理中断。

核心态到用户态：当操作系统内核完成了系统调用或中断处理等任务后，会将控制权返回给用户程序，从而从核心态切换回用户态。

  
**安全性**

用户态：由于权限受限，用户态程序的错误或恶意行为通常不会对整个系统造成严重的破坏。即使一个用户态程序崩溃，也只会影响到它自己的运行，不会影响到其他程序和操作系统的核心部分。

核心态：由于拥有高权限，核心态程序的错误可能会导致整个系统崩溃。因此，操作系统内核的代码必须经过严格的测试和验证，以确保其稳定性和安全性。

### 2.6内存管理有哪几种方式?

**单一连续分配**

方式描述：内存被分为系统区和用户区两部分。在单道程序环境下，系统区仅提供给操作系统使用，用户区则提供给单个用户程序使用。

整个用户区为一个连续的内存空间，一次只能装入一个程序，且程序一旦装入内存，就会一直占据该内存空间，直到程序运行结束。

特点：简单直观，易于实现。只适用于单用户、单任务的操作系统，对内存的利用率低。

**固定分区分配**

方式描述：将内存空间划分为若干个固定大小的分区，每个分区只能装入一道作业。分区大小可以相等，也可以不等。作业在执行过程中不会改变其所在分区的大小，也不能移动到其他分区。

特点：可以支持多道程序并发执行，但由于分区大小固定，可能会出现内存浪费的情况。例如，当一个小作业被分配到一个大分区时，会浪费一部分内存空间。缺乏灵活性，当程序大小与分区大小不匹配时，需要进行复杂的内存分配策略调整。

**动态分区分配**

方式描述：不预先划分固定的分区，而是在作业装入内存时，根据作业的实际需求动态地划分内存空间。

系统维护一个空闲分区表或空闲分区链，记录内存中的空闲分区情况。当有新作业需要装入内存时，系统从空闲分区中选择一个合适的分区分配给该作业。

特点：提高了内存利用率，能够更灵活地适应不同大小的作业需求。可能会产生外部碎片，即随着内存的不断分配和回收，内存中会出现一些小的、不连续的空闲分区，这些空闲分区可能无法满足较大作业的需求。

### 2.7分页和分段有什么区别?

分页和分段是两种不同的内存管理方式，它们的区别主要体现在以下几个方面：

**基本单位**

分页：以固定大小的页为单位将内存和程序逻辑空间进行划分。页的大小通常是由操作系统决定的，并且在整个系统中是固定的。例如，常见的页大小可能是 4KB 或 8KB。

分段：以不定长的段为单位将程序逻辑空间进行划分。段的大小根据程序的逻辑结构而定，可以是不同的长度。每个段具有独立的逻辑意义，如代码段、数据段、堆段、栈段等。

**地址空间划分**

分页：将程序的逻辑地址空间和内存空间都划分为页，通过页表进行映射。逻辑地址由页号和页内偏移组成，通过页表可以找到对应的物理页框号，再加上页内偏移得到物理地址。

分段：将程序的逻辑地址空间划分为不同的段，每个段有自己的段号和段内偏移。通过段表进行映射，将段号转换为物理地址的起始位置，再加上段内偏移得到物理地址。

**信息保护**

分页：主要通过页表中的访问权限位来实现对不同页面的访问控制。例如，可以设置页面为只读、读写或执行等不同的权限。但对于整个程序来说，分页的保护粒度相对较粗。

分段：由于每个段具有独立的逻辑意义，因此可以更精细地进行信息保护。例如，可以对代码段设置为只读，防止被意外修改；对数据段设置不同的读写权限等。

**程序的逻辑结构体现**

分页：分页对程序的逻辑结构没有直接的体现，它主要是从内存管理的角度出发，将程序和内存划分为固定大小的页，以提高内存利用率和方便内存分配。

分段：分段能够更好地体现程序的逻辑结构，程序员可以根据程序的不同部分（如代码、数据、栈等）进行分段，使得程序的组织更加清晰，便于开发和维护。

**外部碎片和内部碎片**

分页：分页会产生一定的内部碎片，即每个页的最后一部分可能未被完全使用，但由于页的大小固定，不会产生外部碎片。

分段：分段可能会产生外部碎片，即随着程序的运行和内存的分配回收，内存中可能会出现一些不连续的小空闲段，这些空闲段可能无法满足较大段的需求。但由于段的大小不固定，通常不会产生内部碎片。

### 2.8页面置换算法有哪些?

页面置换算法是在内存管理中用于决定当内存已满时，选择哪个页面换出到外存以腾出空间给新页面的策略。

**以下是几种常见的页面置换算法：**  
  
(1)最佳置换算法（Optimal Page Replacement）

原理：选择未来最长时间内不会被访问的页面进行置换。这是一种理想的算法，因为它需要预先知道每个页面在未来的访问情况，实际上是无法实现的，但可以作为其他算法性能的比较标准。

举例：假设有一个内存可以容纳 3 个页面，页面引用序列为 7、0、1、2、0、3、0、4、2、3、0、3、2、1、2、0、1、7、0、1。一开始内存为空，依次装入 7、0、1。当需要装入 2 时，根据最佳置换算法，会选择未来最长时间不会被访问的页面，假设已知未来的访问顺序，此时会选择 7 进行置换，因为 7 在未来最远的位置才会被再次访问。

(2)先进先出置换算法（First-In-First-Out，FIFO）

原理：选择在内存中驻留时间最长的页面进行置换，即最先进入内存的页面最先被换出。可以用一个队列来实现，新页面进入队列尾，被置换的页面从队列头取出。

举例：对于上述页面引用序列，按照 FIFO 算法，当需要装入新页面时，总是选择最先进入内存的页面进行置换。比如，在装入页面 2 时，由于 7 是最先进入内存的，所以会置换掉 7。

(3)最近最久未使用置换算法（Least Recently Used，LRU）

原理：选择最近最长时间未被访问的页面进行置换。需要记录每个页面的访问时间，当发生缺页中断时，选择访问时间最早的页面进行置换。

举例：对于页面引用序列，使用 LRU 算法时，会记录每个页面的最后一次访问时间。当需要装入页面 2 时，会检查哪个页面是最近最久未被访问的。假设在当前时刻，页面 7 是最近最久未被访问的，就置换掉 7。

(4)时钟置换算法（Clock Page Replacement）

原理：也称为第二次机会算法。把内存中的所有页面组成一个循环队列，并有一个指针指向最老的页面。当发生缺页中断时，检查指针所指页面的访问位，如果访问位为 0，就置换该页面；如果访问位为 1，就将访问位清零，并移动指针到下一个页面，重复这个过程，直到找到一个访问位为 0 的页面进行置换。

举例：假设内存中有四个页面，页面引用序列为 1、2、3、4、1、2、5、1、2、3、4、5。初始时，指针指向第一个页面。当需要装入新页面时，指针依次检查每个页面的访问位。如果访问位为 1，就将其清零并继续检查下一个页面。当找到一个访问位为 0 的页面时，就置换该页面。

(5)最少使用置换算法（Least Frequently Used，LFU）

原理：选择在一段时间内使用次数最少的页面进行置换。需要记录每个页面的使用次数，当发生缺页中断时，选择使用次数最少的页面进行置换。

举例：对于页面引用序列，使用 LFU 算法时，会记录每个页面的使用次数。当需要装入新页面时，会选择使用次数最少的页面进行置换。比如，在一段时间内，页面 7 的使用次数最少，那么当需要置换页面时，就会选择 7 进行置换。

### 2.9什么是虚拟内存?

虚拟内存是一种计算机系统内存管理技术。它通过将一部分硬盘空间模拟成内存来使用，为每个进程提供了一个连续的、较大的地址空间，这个地址空间独立于实际的物理内存。

**(1)工作原理**

地址映射：当程序运行时，它使用的是虚拟地址。操作系统通过内存管理单元（MMU）将虚拟地址转换为物理地址。这个转换过程是通过页表来实现的，页表记录了虚拟页面和物理页面的对应关系。

例如，程序访问虚拟地址 0x12345678，MMU 根据页表查找该虚拟地址对应的物理地址。如果该虚拟页面在物理内存中，就可以直接访问；如果不在，就会触发缺页中断。

缺页中断处理：当发生缺页中断时，操作系统会将所需的页面从硬盘（虚拟内存的存储位置）加载到物理内存中，并更新页表，使程序能够继续执行。同时，操作系统可能会将一些暂时不使用的页面从物理内存中换出到硬盘上，以释放物理内存空间供其他程序使用。

例如，程序需要访问一个不在物理内存中的页面，操作系统会从硬盘上找到该页面，将其加载到物理内存中，并更新页表，使程序能够继续访问该页面。

**(2)作用**

扩大内存容量：物理内存的容量是有限的，而虚拟内存可以利用硬盘空间来模拟更大的内存空间。这使得计算机能够运行更大的程序和处理更多的数据，而不受物理内存容量的限制。

例如，一个需要大量内存的图形处理软件可以在物理内存较小的计算机上运行，因为虚拟内存可以提供额外的内存空间。

实现内存隔离：每个进程都有自己独立的虚拟地址空间，这使得不同进程之间的内存相互隔离。一个进程不能直接访问另一个进程的内存空间，从而提高了系统的安全性和稳定性。

例如，一个进程中的错误不会影响到其他进程的运行，因为它们的内存空间是独立的。

便于内存管理：虚拟内存使得操作系统能够更方便地管理内存。操作系统可以根据需要将页面从物理内存换出到硬盘上，或者从硬盘加载到物理内存中，从而实现内存的动态分配和回收。

例如，当系统内存紧张时，操作系统可以将一些不常用的页面换出到硬盘上，以释放内存空间供其他程序使用。

支持多任务：虚拟内存为多任务操作系统提供了必要的支持。每个进程都有自己独立的虚拟地址空间，使得多个进程可以同时运行，而不会相互干扰。

例如，在一个多任务操作系统中，多个程序可以同时运行，每个程序都有自己的虚拟内存空间，操作系统可以根据需要在不同的进程之间切换，实现多任务的并发执行。

### 2.10为什么虚拟地址空间切换会比较耗时?

虚拟地址空间切换之所以会比较耗时，主要有以下几个原因：

- 上下文切换：当进程发生切换时，需要保存当前进程的上下文信息（包括寄存器状态、程序计数器等），并加载新进程的上下文信息。这个过程需要进行多次寄存器和内存的读写操作，导致时间开销。
    
- 页表切换：每个进程都有自己独立的页表，用于将虚拟地址映射到物理地址。当发生进程切换时，需要刷新页表以更新虚拟地址与物理地址的映射关系。页表的切换涉及到内存访问和TLB（Translation Lookaside Buffer）缓存的失效，增加了额外的开销。
    
- 缓冲区失效：在进行进程切换时，CPU缓存中保存着前一个进程的数据和指令。当发生切换时，新进程需要重新加载自己的数据和指令到CPU缓存中，这个过程称为缓冲区失效，会造成一定延迟。
    
- 内核态与用户态转换：虚拟地址空间切换通常伴随着从用户态到内核态或者从内核态回到用户态的转换。这种模式转换需要进行特权级的切换和一些额外的操作，导致了额外的时间开销。
    

### 2.11虚拟内存和物理内存怎么对应?

虚拟内存和物理内存之间的对应关系通过页表来实现。操作系统将进程的虚拟地址空间划分为固定大小的页面（通常是4KB），并将每个页面映射到物理内存中的某个页面框（也是4KB）。这种映射关系由页表记录和管理。

当进程访问虚拟地址时，处理器会检查相应的页表项，根据页表项中记录的映射信息将虚拟地址转换为物理地址。如果该页面在物理内存中，则直接使用对应的物理地址进行访问；如果该页面不在物理内存中，则触发缺页异常，操作系统会负责从磁盘上将相应的页面调入到空闲的物理内存页面框中，并更新页表以反映新的映射关系。

通过虚拟内存和物理内存之间的对应关系，操作系统可以有效地管理可用内存资源，使得每个进程可以享有一定量的私有地址空间，并且不需要连续、固定大小的物理内存空间来支持进程运行。这种机制提供了更高效、更灵活地使用内存资源的方式，并且允许多个进程同时运行在一个有限容量的物理内存上。

### 2.12请求页面置换策略有哪些方式?他们的区别是什么?各自有什么算法解决?

请求页面置换策略有以下几种方式，它们主要根据不同的算法来选择被替换的页面：

- 先进先出（FIFO）：最早进入内存的页面会被优先替换出去。这种策略比较简单，但可能导致"先进入"的页面实际上是频繁使用的，而频繁使用的页面却被替换出去。
    
- 最近未使用（LRU）：最长时间没有被访问过的页面会被优先替换出去。这种策略认为，最近很长时间都没有被访问到的页面可能很可能在将来也不会再被访问到。
    
- 最少使用（LFU）：在一段时间内使用次数最少的页面会被优先替换出去。这种策略认为，使用次数少的页面可能是冷门数据或者暂时性需要，可以腾出空间给更常用的数据。
    
- 时钟（Clock）：以一个环形链表结构维护内存中所有页面，并设置一个指针指向其中一个页。当发生缺页中断时，按顺序扫描页表找到第一个"未修改"位为0的页，并进行替换。如果遇到全部为1，则将所有位重新置为0后再继续扫描。
    
- 最佳（OPT）：根据未来的访问情况预测哪个页面最长时间内不会再被访问到，并将其替换出去。这种策略是理论上的最佳策略，但在实际中很难准确预测未来的访问模式。
    

每种置换策略都有其独特的优缺点和适用场景。FIFO简单易实现，但对于热门数据可能效果较差；LRU可以比较准确地判断出最近最少使用的页面，但需要维护额外的数据结构以记录访问顺序；LF

### 2.13什么是缓存一致性问题？如何解决？

缓存一致性问题是指在多级缓存系统中，由于数据的复制和缓存更新操作可能存在延迟或者并发访问的情况下，导致不同缓存之间的数据不一致。

解决缓存一致性问题的方法有以下几种：

- 总线锁/总线嗅探：通过在总线上设置锁定信号或者嗅探其他设备对总线上数据的读写操作来实现一致性。当一个设备要修改共享数据时，会向其他设备发送锁定信号，其他设备收到后暂停对该数据的访问。
    
- 缓存一致性协议：如MESI（Modified, Exclusive, Shared, Invalid）等协议，通过协议规定各级缓存之间的数据状态转换和通信方式。每个缓存都会维护一个标志位表示数据状态，并根据读写操作进行状态转换以保证数据一致性。
    
- 写回策略与写直达策略：在多级缓存结构中，可以采用写回策略（Write Back）或者写直达策略（Write Through）来管理缓存与主内存之间的数据同步。写回策略将修改的数据先保存在本地缓存中，并在合适时机再写入主内存；写直达策略则在修改数据的同时立即更新主内存。通过合理选择策略，可以保证数据在多级缓存中的一致性。
    
- 屏障指令和原子操作：使用特定的屏障指令或者原子操作来对共享数据进行同步。这些指令能够确保在其之前的所有读写操作都已经完成，从而避免了并发访问导致的数据不一致问题。
    
- 缓存失效/刷新机制：当某个缓存被修改时，需要将相应的副本失效或者刷新，使其他缓存中对应的数据无效。可以通过广播、通知等方式实现缓存失效或刷新，并及时更新其他缓存中的数据。
    

### 2.14内存管理单元（MMU）的作用是什么？

内存管理单元（MMU）是计算机系统中的一个重要组成部分，其作用是实现虚拟内存和物理内存之间的转换和管理。具体来说，MMU的主要功能包括：

- 地址映射：将程序使用的虚拟地址转换为对应的物理地址。由于虚拟地址空间可以比实际物理内存空间大得多，MMU通过页表或者段表等数据结构来维护虚拟地址到物理地址之间的映射关系。
    
- 内存保护：通过设置页面级别的访问权限位，MMU可以限制程序对特定内存区域的访问权限，以提高系统安全性和稳定性。
    
- 页面交换与置换：当物理内存不足时，MMU可以通过页面交换或置换策略将一部分页面暂时写入磁盘，从而释放出物理内存供其他页面使用。
    
- 缓存控制：MMU还负责处理与CPU缓存相关的操作，如缓存一致性、缓冲区失效等。
    
- 错误检测与处理：MMU能够监测并报告一些常见的内存错误，如页面不存在、写保护异常等，并采取相应措施进行处理或通知操作系统。
    

### 2.15什么是堆和栈？它们的区别是什么？

堆和栈是计算机内存中用于存储数据的两个重要区域，它们有以下几个主要区别：

- 内存分配方式：栈（stack）采用自动分配和释放的方式，由编译器自动管理；而堆（heap）则需要手动进行分配和释放。
    
- 空间大小限制：栈的空间通常较小，受限于系统设置的栈大小；而堆的空间较大，通常只受系统总体内存大小限制。
    
- 分配效率：由于栈采用自动分配方式，其分配和释放速度较快；而堆的分配与释放相对较慢，涉及到更复杂的内存管理。
    
- 数据生命周期：栈中存储的数据具有局部性，随着函数执行结束或作用域结束会被自动释放；而堆中存储的数据可以持久存在，在手动释放前都会一直存在。
    
- 存储内容类型：栈主要用于保存基本类型变量、函数调用、局部变量等短期使用的数据；而堆则常用来存储对象、数组等在运行时才确定大小且需要长期保存的数据。
    

## 三、文件系统

### 3.1什么是文件系统？常见的文件系统有哪些？

文件系统是操作系统用于管理和组织存储在计算机上的文件和目录的一种方法。它提供了文件的创建、读取、写入、删除等基本操作，并为文件分配磁盘空间以及记录文件的位置信息。常见的文件系统包括：

- FAT（File Allocation Table）：FAT是DOS和Windows操作系统中使用的一种简单文件系统，包括FAT12、FAT16和FAT32三个版本。它们适用于较小容量的存储设备，如磁盘和闪存。
    
- NTFS（New Technology File System）：NTFS是Windows NT系列操作系统中使用的高级文件系统。它支持更大容量的存储设备，提供了许多高级特性，如权限控制、日志记录、加密等。
    
- ext4（Fourth Extended File System）：ext4是Linux操作系统中最常用的默认文件系统。它是对ext3文件系统进行改进得到的，支持更大容量和更高性能，并提供了日志功能。
    
- HFS+（Hierarchical File System Plus）：HFS+是苹果公司开发并广泛应用于Mac OS X操作系统上的文件系统。它支持Unicode字符编码，具有元数据日志、快速查找和压缩等特性。
    
- APFS（Apple File System）：APFS是苹果推出的最新一代文件系统，取代了HFS+。它针对固态硬盘和闪存进行了优化，提供了更好的性能、安全性和可靠性。
    

### 3.2文件的物理结构有哪些？

- 顺序文件：数据按照逻辑顺序依次存储在磁盘或其他存储介质上。读取时需要按照顺序逐个读取，无法直接跳转到指定位置。
    
- 索引文件：数据被分成固定大小的块，并建立一个索引表来记录每个块所在的位置。通过索引表可以快速找到指定数据块的位置，实现随机访问。
    
- 链接文件：将文件中的数据块链接在一起形成链表结构。每个数据块都包含了下一个数据块的地址，通过遍历链表可以获取整个文件内容。
    
- 索引节点（i-node）文件：在UNIX/Linux系统中常见，将文件信息和数据块的地址等元数据存储在一个索引节点中。通过索引节点可以快速查找和管理文件。
    
- 散列文件：根据数据内容进行散列计算得到唯一散列值，并将散列值作为关键字来存储和检索数据。不同散列值对应不同存储位置，实现高效的查找。
    

### 3.3文件的访问控制方式有哪些？

- 权限位（Permission-based）：操作系统通过给文件分配权限位来控制对文件的访问。常见的权限包括读取（Read）、写入（Write）和执行（Execute）等。根据不同用户或用户组，可以设置不同的权限。
    
- 访问列表（Access Control List, ACL）：ACL是一种更为灵活的访问控制方式，允许在文件上定义多个用户或用户组，并为每个用户或用户组指定相应的访问权限。相较于权限位，ACL提供了更细粒度的控制。
    
- 角色基础访问控制（Role-Based Access Control, RBAC）：RBAC是一种基于角色的访问控制模型，其中将权限分配给角色而不是直接分配给个人用户。通过将用户与适当角色相关联，可以简化管理并提供可扩展性。
    
- 安全标签（Security Labels）：安全标签是在某些操作系统中使用的一种机制，通过为每个文件分配一个安全标签来确定哪些主体具有对该文件进行操作的权限。这种机制通常用于多级安全环境。
    
- 加密（Encryption）：加密技术可以确保只有拥有正确密钥或密码的人能够解密和访问文件内容。通过加密，即使未经授权访问文件也无法读取其内容。
    

### 3.4解释一下文件系统的挂载和卸载过程。

文件系统的挂载和卸载是操作系统中管理存储设备与文件系统之间关联的过程。

挂载（Mount）过程：

- 确认存储设备：首先，操作系统需要识别和确认要挂载的存储设备，例如硬盘、分区、USB驱动器等。
    
- 分配挂载点：操作系统会为要挂载的文件系统分配一个挂载点，这是一个目录或路径，用于表示文件系统在整个目录树中的位置。
    
- 挂载命令：使用特定的挂载命令（如mount），将文件系统连接到指定的挂载点。该命令通常需要指定文件系统类型、设备名称和挂载选项等参数。
    
- 文件系统准备：在进行实际的挂载之前，操作系统会执行一系列初始化步骤，包括检查文件系统结构、建立索引等。
    

卸载（Unmount）过程：

- 停止对文件的访问：确保没有任何进程正在使用该文件系统上的文件或目录。
    
- 卸载命令：使用特定的卸载命令（如umount），将文件系统从其挂载点断开连接。
    
- 同步数据：为了确保所有数据都已写入磁盘并保存完整性，在卸载之前可能会执行数据同步操作。
    
- 卸载完成：成功卸载后，相关的挂载点将不再是有效的文件系统。
    

需要注意的是，正确地进行文件系统的挂载和卸载操作是保证数据安全、避免损坏和数据丢失的重要步骤。因此，在进行挂载和卸载时，需要确保没有未完成的写入操作，并在断开连接之前对数据进行同步。

### 3.5什么是文件索引？有哪些类型的文件索引？

文件索引是一种用于加快文件系统中文件访问速度的数据结构，它保存了有关文件和目录的元数据信息。文件索引可以帮助操作系统快速定位和访问特定文件或目录的位置和属性。以下是几种常见的文件索引类型：

- 线性索引（Linear Indexing）：线性索引将所有文件项按照一定顺序排列，并为每个文件项分配唯一的标识符。通过这个标识符，可以直接找到相应的文件项，进而获取到文件的物理位置和其他属性。但随着文件数量增加，线性索引可能会导致查询效率下降。
    
- 索引节点（Inode）：Unix/Linux系统中广泛使用的一种索引方式。每个文件都有一个对应的索引节点，其中包含了与该文件相关的元数据信息（如权限、拥有者、大小等）以及指向实际数据块所在位置的指针。
    
- 扩展存储器索引（Extensible Storage Engine Indexing）：扩展存储器数据库系统（如Microsoft Exchange Server）使用B+树或类似结构来构建索引。这些树形结构能够高效地支持范围查询和排序等操作。
    
- 散列表索引（Hash Indexing）：散列表是另一种常见的索引方式，它通过将关键字（如文件名）转换为散列值，并将该值与对应的数据项关联起来。散列表索引可以快速地进行查找操作，但不支持范围查询。
    
- 倒排索引（Inverted Indexing）：主要用于全文搜索引擎中，它将词条映射到包含该词条的文件集合。倒排索引能够高效地实现关键字搜索和文本匹配。
    

### 3.6文件系统的性能优化方法有哪些？

- 合理选择文件系统类型：不同的文件系统类型对性能有不同的影响，如EXT4、NTFS、XFS等。根据具体应用场景和需求选择适合的文件系统类型。
    
- 优化磁盘布局：良好的磁盘布局可以提高文件读写效率。可以通过分区、RAID配置、磁盘条带化等方式来优化磁盘布局，提高磁盘访问速度和可靠性。
    
- 文件预分配和延迟分配：在创建大型文件时，预先为其分配足够的空间，避免频繁地进行扩展操作。延迟分配则是推迟实际分配磁盘空间的时间，直到真正需要写入数据时再进行分配。
    
- 使用快速存储设备：将关键数据放置在快速存储设备（如固态硬盘）上，以加快读写速度。
    
- 缓存技术：利用缓存机制提高文件系统访问速度。操作系统会将最近访问过的数据缓存在内存中，在后续访问时可直接从内存读取，避免了频繁的物理读取操作。
    
- 数据压缩与去重：对于一些存储密集型应用，可以使用数据压缩和去重技术来节省磁盘空间，提高存储效率。
    
- 文件系统日志：启用文件系统的日志功能（如Journaling），可以在发生意外断电等异常情况下快速恢复文件系统的一致性。
    
- 并发控制：合理处理多个并发访问请求，采用适当的并发控制策略，以避免资源竞争和提高整体性能。
    
- 定期进行磁盘碎片整理：定期进行磁盘碎片整理操作，将分散的文件碎片重新组织到连续的物理空间中，提高文件读取速度。
    
- 调优参数设置：根据实际需求，调整文件系统相关参数，如缓存大小、最大打开文件数等。这些参数设置对于不同应用场景可能有不同的影响。
    

### 3.7如何恢复损坏的文件系统？

- 确认损坏类型：首先需要确认文件系统的损坏类型，可能是因为硬件故障、意外断电、病毒攻击等引起的。
    
- 备份数据：在进行任何修复操作之前，务必备份所有重要数据。这是为了避免进一步损坏或数据丢失。
    
- 使用内置工具：许多操作系统都提供了内置的文件系统检测和修复工具。例如，Windows下的chkdsk命令、Linux下的fsck命令等。运行相应的工具来扫描和修复文件系统错误。
    
- 使用第三方工具：如果内置工具无法解决问题，可以尝试使用专门的第三方文件系统恢复软件。有许多商业和免费可用的工具，如TestDisk、EaseUS Data Recovery Wizard、R-Studio等。
    
- 专业数据恢复服务：如果以上方法都无法成功恢复损坏的文件系统，可以考虑寻求专业数据恢复服务。有些公司专门从物理磁盘上恢复数据，并提供高级技术支持。
    

无论采取哪种方法，请记住在进行任何操作之前先备份数据，并确保充分了解所执行操作的风险和后果。

## 四、设备管理

### 4.1什么是设备驱动程序？它的作用是什么？

设备驱动程序是一种软件，它充当操作系统和硬件设备之间的接口，用于控制和管理硬件设备的操作。它的作用是将抽象的操作系统命令转化为硬件设备可以理解和执行的指令，以实现对硬件设备的有效控制。

设备驱动程序通常由设备厂商或第三方开发者编写，并与特定类型的硬件设备相匹配。每个硬件设备都有其独特的驱动程序，例如显示器、键盘、鼠标、打印机、网卡等。主要作用包括：

- 设备初始化和配置：驱动程序负责初始化硬件设备并进行适当的配置，以便让操作系统正确识别和使用该设备。
    
- 提供接口和功能：驱动程序提供了操作系统与硬件之间的交互接口，使得应用程序能够通过操作系统调用来访问和控制该设备。
    
- 数据传输和处理：驱动程序负责处理从应用程序发送给设备或从设备接收到的数据，并进行必要的转换、处理或传输。
    
- 错误检测和处理：驱动程序监测并处理与硬件相关的错误或异常情况，如故障、断开连接等，并向操作系统报告相关信息。
    
- 资源管理：驱动程序负责分配和释放设备所需的系统资源，如内存、中断、DMA通道等，以确保多个设备之间的协调工作。
    

### 4.2设备管理的主要功能有哪些？

- 设备发现与识别：设备管理负责检测系统中连接的设备，并确定其类型、特性和能力，以便正确配置和使用。
    
- 设备驱动程序加载与安装：设备管理负责加载适当的设备驱动程序，将其与硬件设备关联起来，并确保它们在系统启动时自动加载。
    
- 设备状态监测与控制：设备管理监测已连接的设备状态，例如是否正常工作、是否存在故障等，并采取相应的措施进行修复或通知用户。
    
- 设备资源分配与冲突解决：设备管理负责分配系统资源给不同的设备，并解决多个设备之间可能出现的资源冲突，如中断冲突、内存地址冲突等。
    
- 设备配置与设置：通过设备管理，可以对硬件设备进行适当的配置和设置，包括参数调整、协议选择、速率设置等，以满足特定需求。
    
- 设备驱动程序更新与维护：当新版本的设备驱动程序发布或存在漏洞时，设备管理可负责更新已安装的驱动程序并进行维护，以提高系统兼容性和安全性。
    
- 故障排除与错误处理：当硬件设备发生故障或出现错误时，设备管理负责检测、记录和报告问题，并提供相应的故障排除和错误处理方法。
    

### 4.3I/O 控制方式有哪些？

- 程序查询方式（Programmed I/O）：在程序中使用指令来轮询设备的状态，判断是否就绪并进行数据的读取或写入。这是最简单的一种控制方式，但也是最浪费 CPU 时间和系统资源的方式。
    
- 中断驱动方式（Interrupt-driven I/O）：设备在完成操作时发出中断信号，通知 CPU 设备已经就绪。CPU 通过中断处理程序响应设备请求，并进行相应的读取或写入操作。
    
- 直接存储器访问方式（Direct Memory Access, DMA）：使用专门的 DMA 控制器，将数据直接从设备传输到内存或从内存传输到设备，而不需要每次都经过 CPU 参与。这样可以减少对 CPU 的负载，提高数据传输效率。
    
- 通道方式（Channel I/O）：通道是一个独立的硬件子系统，具有自己的控制逻辑和寄存器。它能够管理多个设备并独立地执行输入/输出操作，从而进一步减少对 CPU 的干预。
    

这些控制方式在不同情况下具有各自的优缺点，并根据特定需求选择合适的方式来实现高效可靠的输入/输出操作。

### 4.4解释一下中断的作用和处理过程。

中断是一种计算机系统的机制，用于处理硬件设备或软件事件发生时对CPU的通知和打断。中断可以分为外部中断（来自外部设备）和内部中断（由CPU或程序生成）。

中断的作用是使CPU能够及时响应重要事件，而不需要持续地轮询或等待事件发生。它提高了系统的并发性、实时性和效率。处理中断的过程如下：

- 当一个设备准备好要进行输入/输出操作时，它会向CPU发送一个中断请求信号。
    
- CPU接收到中断请求后，会立即暂停当前正在执行的任务，并将当前状态保存在堆栈上。
    
- CPU跳转到预定义的中断处理程序（Interrupt Service Routine, ISR），开始执行特定的中断处理代码。
    
- 中断处理程序执行完成后，CPU从堆栈上恢复之前保存的状态，并返回到原来被打断的地方，继续执行先前被暂停的任务。
    

在处理完一个中断后，CPU会检查是否还有其他挂起的更高优先级的中断请求需要处理。如果有，则按照优先级顺序继续处理下一个中断。

### 4.5如何提高设备的 I/O 性能？

要提高设备的I/O性能，可以考虑以下几个方面：

- 使用更快的存储介质：将传统机械硬盘（HDD）升级为固态硬盘（SSD），因为SSD具有更高的读写速度和更低的访问延迟。
    
- RAID配置：使用RAID（冗余阵列磁盘）技术将多个物理磁盘组合起来，以提供更好的性能和冗余保护。常见的RAID级别包括RAID 0、RAID 1、RAID 5等。
    
- 文件系统优化：选择适当的文件系统，如ext4、NTFS等，并进行相应的优化设置。例如，调整磁盘缓存策略、启用适当的日志选项等。
    
- 缓存机制：通过使用缓存技术，如读写缓存或页面缓存，可以显著提高I/O性能。这些缓存可以在内存中保存经常访问或写入的数据，从而加快读取和写入操作。
    
- 硬件升级：如果可能，可以考虑升级设备的硬件组件，如CPU、内存和扩展控制器。这样可以提供更好的计算和处理能力，改善整体I/O性能。
    
- 调整操作系统参数：对操作系统进行一些参数调整，如增加文件描述符限制、优化内核调度器等，可以提高I/O性能。
    
- 使用异步I/O：使用异步I/O技术（例如epoll在Linux上）可以允许应用程序并发地执行多个I/O操作，提高吞吐量和响应性能。
    
- 数据压缩和压缩：对于适用的场景，可以使用数据压缩和解压缩技术，减少传输和存储所需的数据量，从而提高I/O性能。
    

  

2023年往期回顾

  

[C/C++发展方向（强烈推荐！！）](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247487749&idx=1&sn=e57e6f3df526b7ad78313d9428e55b6b&chksm=cfb9586cf8ced17a8c7830e380a45ce080c2b8258e145f5898503a779840a5fcfec3e8f8fa9a&scene=21#wechat_redirect)  

[Linux内核源码分析（强烈推荐收藏！](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247487832&idx=1&sn=bf0468e26f353306c743c4d7523ebb07&chksm=cfb95831f8ced127ca94eb61e6508732576bb150b2fb2047664f8256b3da284d0e53e2f792dc&scene=21#wechat_redirect)[）](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247487832&idx=1&sn=bf0468e26f353306c743c4d7523ebb07&chksm=cfb95831f8ced127ca94eb61e6508732576bb150b2fb2047664f8256b3da284d0e53e2f792dc&scene=21#wechat_redirect)  

[从菜鸟到大师，用Qt编写出惊艳世界应用](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247488117&idx=1&sn=a83d661165a3840fbb23d0e62b5f303a&chksm=cfb95b1cf8ced20ae63206fe25891d9a37ffe76fd695ef55b5506c83aad387d55c4032cb7e4f&scene=21#wechat_redirect)  

[存储全栈开发：构建高效的数据存储系统](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247487696&idx=1&sn=b5ebe830ddb6798ac5bf6db4a8d5d075&chksm=cfb959b9f8ced0af76710c070a6db2677fb359af735e79c6378e82ead570aa1ce5350a146793&scene=21#wechat_redirect)

[突破性能瓶颈：释放DPDK带来无尽潜力](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247488150&idx=1&sn=2cc5ace4391d4eed060fa463fc73dd92&chksm=cfb95bfff8ced2e9589eecd66e7c6e906f28626bef6c1bce3fa19ae2d1404baa25ba3ebfedaa&scene=21#wechat_redirect)

[嵌入式音视频技术：从原理到项目应用](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247488135&idx=1&sn=dcc56a3af5401c338944b9b94f24c699&chksm=cfb95beef8ced2f8231c647033188be3ded88cbacf7d75feab3613f4d7f8fd8e4c8106ac88cf&scene=21#wechat_redirect)

[](http://mp.weixin.qq.com/s?__biz=MzIwNzA1OTA2OQ==&mid=2657215412&idx=1&sn=d3c64ac21056b84814db9903b656853a&chksm=8c8d62a6bbfaebb09df1f727e201c401a1663596a719fa9cb4c7859158e62ebedb5bd5f13b8f&scene=21#wechat_redirect)[C++游戏开发，基于魔兽开源后端框架](http://mp.weixin.qq.com/s?__biz=Mzg4NDQ0OTI4Ng==&mid=2247486920&idx=1&sn=82ca8a72473850e431c01e7c39d8c8c0&chksm=cfb944a1f8cecdb7051863f58d334ff3dea8afae1ecd8bc693287b2f483d2ce8f94eed565253&scene=21#wechat_redirect)

C/C++开发103

面试八股文11

校招应届生14

C/C++开发 · 目录

上一篇美团到店研发一面面经（已挂）下一篇大疆最新硬件工程师面试题汇总（附答案）

Reads 1835

​